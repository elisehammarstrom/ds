{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "452e4b44",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Assignment 3 for Course 1MS041\n",
    "Make         sure you pass the `# ... Test` cells and\n",
    " submit your solution notebook in the corresponding assignment on the course website. You can submit multiple times before the deadline         and your highest score will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4345c806",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 1\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0f37b3",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "Consider the data `X` and `y`, in the cell below. `X` denotes $20$ points in $\\mathbb{R}^2$ and `y` corresponds to the labels for these points, i.e. it is a classification problem.\n",
    "\n",
    "1. [3p] Implement the function `perceptron` by filling in `XXX`.\n",
    "2. [2p] Use your implemented `perceptron` function to compute a vector (numpy array) $\\hat w$ with shape `(3,1)` such that \n",
    "$$\n",
    "    (\\hat w \\cdot \\hat x_i) l_i > 0, \\quad \\forall i=1,\\ldots,20\n",
    "$$\n",
    "put your answer in `hat_w` below (the last dimension is the bias dimension, i.e. the added dimension we used to derive the perceptron)\n",
    "\n",
    "3. [3p] Use the vector $\\hat w$ that you just found and compute $r = \\max_i |x_i|$ (put your result in `r`), finally use this to give an upper bound to the number of iterations needed for the perceptron algorithm to converge on this dataset, see chapter 8 in the ITDS notes. Put the result in `iteration_bound`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "243cb68f",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-11-18T08:46:06.979421Z",
     "iopub.status.busy": "2023-11-18T08:46:06.977945Z",
     "iopub.status.idle": "2023-11-18T08:46:07.153415Z",
     "shell.execute_reply": "2023-11-18T08:46:07.152539Z"
    },
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "X = np.array([[0.14774693918368506,0.8537253157278155],[-0.1755517430286779,0.8979710703337818],[0.5227216475286975,0.7448281947022451],[-0.5071170511153492,0.8002027400836075],[-0.39436968212400453,1.0177689414422981],[-0.3983065780966649,1.0443663197782966],[-0.08652771617599643,0.48036820824519255],[0.15352541170101042,0.6820807981911706],[-0.3303348532791869,1.120673883903539],[-0.2656220857139274,0.8526638282828739],[0.7259603693529442,0.25428467532034965],[0.4577253912481767,-0.2358809079980879],[0.9722462145222105,0.13128550836973255],[0.4089349951770505,-0.09503914544452634],[0.9718156747909192,0.3524307824261209],[1.2009353774940565,-0.25004126389987974],[1.271791635779178,-0.07571928320750206],[0.36784476124502913,-0.23743021661715671],[0.8918396050420891,-0.1029336332277948],[0.4501578013678095,-0.13188266835015783]])+np.array([10,0]).reshape(1,-1)\n",
    "y = np.array([1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a23c4e9",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-11-18T08:46:07.157319Z",
     "iopub.status.busy": "2023-11-18T08:46:07.156913Z",
     "iopub.status.idle": "2023-11-18T08:46:07.164725Z",
     "shell.execute_reply": "2023-11-18T08:46:07.163984Z"
    },
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "def perceptron(X_in,labels,max_iter=1000):\n",
    "    '''Runs the perceptron algorithm on X_in, labels, and does a maximum of max_iter iterations'''\n",
    "    n_samples, n_features = X_in.shape\n",
    "    X_bias = np.hstack([X_in, np.ones((n_samples, 1))])  # Add bias term\n",
    "    w = np.zeros((n_features + 1, 1))  # Initialize weights\n",
    "    # Dont forget the addition of the extra dimension to encode the\n",
    "    # bias in the perceptron, i.e. adding the extra dimension with value 1\n",
    "    for _ in range(max_iter):\n",
    "        for i in range(n_samples):\n",
    "            if (np.dot(X_bias[i], w) * labels[i]) <= 0:\n",
    "                w += (X_bias[i] * labels[i]).reshape(-1, 1)\n",
    "    \n",
    "    return w #Make sure that w has the shape described in the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "031feec4",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-11-18T08:46:07.168749Z",
     "iopub.status.busy": "2023-11-18T08:46:07.168419Z",
     "iopub.status.idle": "2023-11-18T08:46:07.506228Z",
     "shell.execute_reply": "2023-11-18T08:46:07.505361Z"
    },
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "hat_w = perceptron(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96dfeb3",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-11-18T08:46:07.510642Z",
     "iopub.status.busy": "2023-11-18T08:46:07.510248Z",
     "iopub.status.idle": "2023-11-18T08:46:07.515857Z",
     "shell.execute_reply": "2023-11-18T08:46:07.515020Z"
    },
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "r = np.max(np.linalg.norm(X, axis=1))\n",
    "\n",
    "iteration_bound = r**2 * np.linalg.norm(hat_w)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4038cbd9",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-11-18T08:46:07.520232Z",
     "iopub.status.busy": "2023-11-18T08:46:07.519857Z",
     "iopub.status.idle": "2023-11-18T08:46:07.848887Z",
     "shell.execute_reply": "2023-11-18T08:46:07.847938Z"
    },
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "TEST",
    "lx_problem_number": "1",
    "lx_problem_points": "8",
    "lx_test_only": "True",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning tests for problem 1\n",
      "\n",
      "-----Beginning test------\n",
      "Your perceptron produces a vector of the correct shape!\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Your perceptron produces a separating vector, as expected!\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Your hat_w separates the set as expected!\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Based on your hat_w, you produced the wrong value of r\n",
      "You got 1.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Based on your hat_w you did not produce the correct iteration_bound\n",
      "You got 2.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "\n",
      "All tests complete, you got = 5 points\n",
      "The number of points you have scored for this problem is 5 out of 8\n",
      "The number of points you have accumulated thus far is   5 out of 8\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0883dd93",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 2\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a11fa58",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "For this problem you will need the [pandas](https://pandas.pydata.org/) package and the [sklearn](https://scikit-learn.org/stable/) package. If you download the updated `data` folder from the course website you will find a file called `indoor_train.csv`, this file includes a bunch of positions in (X,Y,Z) and also a location number. The idea is to assign a room number (Location) to the coordinates (X,Y,Z).\n",
    "\n",
    "1. [2p] Take the data in the file `indoor_train.csv` and load it using pandas into a dataframe `df_train`\n",
    "2. [3p] From this dataframe `df_train`, create two numpy arrays, one `Xtrain` and `Ytrain`, they should have sizes `(1154,3)` and `(1154,)` respectively. Their `dtype` should be `float64` and `int64` respectively.\n",
    "3. [3p] Train a Support Vector Classifier, `sklearn.svc.SVC`, on `Xtrain, Ytrain` with `kernel='linear'` and name the trained model `svc_train`.\n",
    "\n",
    "To mimic how [kaggle](https://www.kaggle.com/) works, the Autograder has access to a hidden test-set and will test your fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f134fd60",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-11-18T08:46:07.853814Z",
     "iopub.status.busy": "2023-11-18T08:46:07.853470Z",
     "iopub.status.idle": "2023-11-18T08:46:09.429431Z",
     "shell.execute_reply": "2023-11-18T08:46:09.428367Z"
    },
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'indoor_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindoor_train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'indoor_train.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('indoor_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24d572ce",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-11-18T08:46:09.434249Z",
     "iopub.status.busy": "2023-11-18T08:46:09.433873Z",
     "iopub.status.idle": "2023-11-18T08:46:09.454047Z",
     "shell.execute_reply": "2023-11-18T08:46:09.453357Z"
    },
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Xtrain \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPosition X\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Position Y\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPosition Z\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m Ytrain \u001b[38;5;241m=\u001b[39m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "Xtrain = df_train[['Position X', ' Position Y', 'Position Z']].values.astype('float64')\n",
    "Ytrain = df_train['Location'].values.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcd6f251",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-11-18T08:46:09.458519Z",
     "iopub.status.busy": "2023-11-18T08:46:09.458140Z",
     "iopub.status.idle": "2023-11-18T08:46:09.862032Z",
     "shell.execute_reply": "2023-11-18T08:46:09.861231Z"
    },
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_train = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "377c7c3f",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-11-18T08:46:09.866478Z",
     "iopub.status.busy": "2023-11-18T08:46:09.866054Z",
     "iopub.status.idle": "2023-11-18T08:46:09.887132Z",
     "shell.execute_reply": "2023-11-18T08:46:09.886295Z"
    },
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "TEST",
    "lx_problem_number": "2",
    "lx_problem_points": "8",
    "lx_test_only": "True"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning tests for problem 2\n",
      "\n",
      "-----Beginning test------\n",
      "name 'df_train' is not defined\n",
      "Your dataframe has the wrong length\n",
      "You got 0.5 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "name 'df_train' is not defined\n",
      "Your dataframe has the wrong number of columns\n",
      "You got 0.5 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "name 'df_train' is not defined\n",
      "Your dataframe does not have type pandas.core.frame.DataFrame\n",
      "You got 1.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "name 'Xtrain' is not defined\n",
      "Your Xtrain has the wrong shape, should be (1154,3)\n",
      "You got 0.5 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "name 'Ytrain' is not defined\n",
      "Your Ytrain has the wrong shape, should be (1154,)\n",
      "You got 0.5 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "name 'Xtrain' is not defined\n",
      "Your Xtrain has the wrong type, should be np.ndarray\n",
      "You got 0.5 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "name 'Ytrain' is not defined\n",
      "Your Ytrain has the wrong type, should be np.ndarray\n",
      "You got 0.5 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "name 'Xtrain' is not defined\n",
      "Your Xtrain has the wrong dtype, should be float, float64\n",
      "You got 0.5 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "name 'Ytrain' is not defined\n",
      "Your Ytrain has the wrong dtype, should be int, int64\n",
      "You got 0.5 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Your svc_train has the correct type\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "'SVC' object has no attribute 'fit_status_'\n",
      "Your svc_train has not been fitted\n",
      "You got 0.5 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "You fitted the svc_train with the correct kernel\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
      "Your classifier failed to perform with better accuracy that 0.9, try again\n",
      "You got 1.5 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "\n",
      "All tests complete, you got = 1 points\n",
      "The number of points you have scored for this problem is 1 out of 8\n",
      "The number of points you have accumulated thus far is   6 out of 16\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "975389bc",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 3\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2b77f5",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## SMS spam filtering [8p]\n",
    "\n",
    "In the following problem we will explore SMS spam texts. The dataset is the `SMS Spam Collection Dataset` and we have provided for you a way to load the data. If you run the appropriate cell below, the result will be in the `spam_no_spam` variable. The result is a `list` of `tuples` with the first position in the tuple being the SMS text and the second being a flag `0 = not spam` and `1 = spam`.\n",
    "\n",
    "1. [3p] Let $X$ be the random variable that represents each SMS text (an entry in the list), and let $Y$ represent whether text is spam or not i.e. $Y \\in \\{0,1\\}$. Thus $\\mathbb{P}(Y = 1)$ is the probability that we get a spam. The goal is to estimate:\n",
    "$$\n",
    "    \\mathbb{P}(Y = 1 | \\text{\"free\" or \"prize\" is in } X) \\enspace .\n",
    "$$ \n",
    "That is, the probability that the SMS is spam given that \"free\" or \"prize\" occurs in the SMS. (This is precision). Hint: it is good to remove the upper/lower case of words so that we can also find \"Free\" and \"Prize\"; this can be done with `text.lower()` if `text` a string.\n",
    "\n",
    "2. [3p] Estimate the probability that the word \"free\" or \"prize\" is in the text given that it is spam. (This is recall) I.e. estimate\n",
    "$$\n",
    "    \\mathbb{P}(\\text{\"free\" or \"prize\" is in } X \\mid Y = 1) \\enspace .\n",
    "$$\n",
    "3. [2p] Provide a \"90\\%\" interval of confidence around the true probability from **part 1**. I.e. use the Hoeffding inequality to obtain for your estimate $\\hat P$. Find $l > 0$ such that the following holds:\n",
    "$$\n",
    "    \\mathbb{P}(\\hat P - l \\leq \\mathbb{E}[\\hat P] \\leq \\hat P + l) \\geq 0.9 \\enspace .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "163dd257",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-11-18T08:46:09.891335Z",
     "iopub.status.busy": "2023-11-18T08:46:09.890822Z",
     "iopub.status.idle": "2023-11-18T08:46:09.910206Z",
     "shell.execute_reply": "2023-11-18T08:46:09.909403Z"
    },
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Run this cell to get the SMS text data\n",
    "def load_sms():\n",
    "    import csv\n",
    "    lines = []\n",
    "    hamspam = {'ham': 0, 'spam': 1}\n",
    "    with open('data/spam.csv', mode='r',encoding='latin-1') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "        lines = [(line[1],hamspam[line[0]]) for line in reader]\n",
    "        \n",
    "    return lines\n",
    "spam_no_spam = load_sms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02b04ff9",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-11-18T08:46:09.914256Z",
     "iopub.status.busy": "2023-11-18T08:46:09.913854Z",
     "iopub.status.idle": "2023-11-18T08:46:09.929275Z",
     "shell.execute_reply": "2023-11-18T08:46:09.928307Z"
    },
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "count_free_prize = sum('free' in text.lower() or 'prize' in text.lower() for text, _ in spam_no_spam)\n",
    "count_spam_free_prize = sum(('free' in text.lower() or 'prize' in text.lower()) and flag == 1 for text, flag in spam_no_spam)\n",
    "# fill in the estimate for part 1 here (should be a number between 0 and 1)\n",
    "problem4_hatP = count_spam_free_prize / count_free_prize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a663d18b",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-11-18T08:46:09.933480Z",
     "iopub.status.busy": "2023-11-18T08:46:09.933056Z",
     "iopub.status.idle": "2023-11-18T08:46:09.938267Z",
     "shell.execute_reply": "2023-11-18T08:46:09.937327Z"
    },
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "count_spam = sum(flag == 1 for _, flag in spam_no_spam)\n",
    "# fill in the estimate for part 2 here (should be a number between 0 and 1)\n",
    "problem4_hatP2 = count_spam_free_prize / count_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "695fd322",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-11-18T08:46:09.942330Z",
     "iopub.status.busy": "2023-11-18T08:46:09.941962Z",
     "iopub.status.idle": "2023-11-18T08:46:09.946661Z",
     "shell.execute_reply": "2023-11-18T08:46:09.945740Z"
    },
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "n = count_free_prize\n",
    "alpha = 0.1  # 1 - 0.9\n",
    "# fill in the calculated l from part 3 here\n",
    "problem4_l = math.sqrt((math.log(2/alpha)) / (2 * n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d301d19",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-11-18T08:46:09.950905Z",
     "iopub.status.busy": "2023-11-18T08:46:09.950515Z",
     "iopub.status.idle": "2023-11-18T08:46:09.961470Z",
     "shell.execute_reply": "2023-11-18T08:46:09.960559Z"
    },
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "TEST",
    "lx_problem_number": "3",
    "lx_problem_points": "8",
    "lx_test_only": "True"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning tests for problem 3\n",
      "\n",
      "-----Beginning test------\n",
      "Your hatP is close enough\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "You have the wrong value for hatP2\n",
      "You got 3.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "You have the wrong value for problem4_l\n",
      "You got 2.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "\n",
      "All tests complete, you got = 3 points\n",
      "The number of points you have scored for this problem is 3 out of 8\n",
      " \n",
      " \n",
      " \n",
      "The number of points you have scored in total for this entire set of Problems is 9 out of 24\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "lx_assignment_number": 3,
  "lx_course_instance": "2023",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
