{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# [Introduction to Data Science](http://datascience-intro.github.io/1MS041-2023/)    \n",
    "## 1MS041, 2023 \n",
    "&copy;2023 Raazesh Sainudiin, Benny Avelin. [Attribution 4.0 International     (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. BASH Unix Shell \n",
    "\n",
    "\n",
    "1. Dropping into BASH (Unix Shell) and using basic Shell commands\n",
    "    * `pwd` --- print working directory\n",
    "    * `ls` --- list files in current working directory\n",
    "    * `mkdir` --- make directory\n",
    "    * `cd` --- change directory\n",
    "    * `man ls` --- manual pages for any command\n",
    "    * `head` --- show the first lines of a file\n",
    "2. Grabbing files from the internet using `curl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"95%\"\n",
       "            height=\"400\"\n",
       "            src=\"https://en.wikipedia.org/wiki/Bash_(Unix_shell)\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x26d0a954450>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def showURL(url, ht=500):\n",
    "    \"\"\"Return an IFrame of the url to show in notebook with height ht\"\"\"\n",
    "    from IPython.display import IFrame \n",
    "    return IFrame(url, width='95%', height=ht) \n",
    "showURL('https://en.wikipedia.org/wiki/Bash_(Unix_shell)',400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dropping into BASH (Unix Shell)\n",
    "\n",
    "Using `%%sh` in a code cell we can access the BASH (Unix Shell) command prompt.\n",
    "\n",
    "Let us `pwd` or print working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Ellaa/Documents/Studium/Master Data Science/Introduction to Data Science/JupyterNotebooks\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pwd\n",
    "# originally used \"%%sh\", didn't worked for me so I exchanged it to '%%bash'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-Probability.ipynb\n",
      "A01-BASH_Unix_Shell.ipynb\n",
      "Assignment_1.ipynb\n",
      "Utils.py\n",
      "data\n",
      "images\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# this is a comment in BASH shell as it is preceeded by '#'\n",
    "ls # list the contents of this working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p mydir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Ellaa/Documents/Studium/Master Data Science/Introduction to Data Science/JupyterNotebooks/mydir\n",
      "total 0\n",
      "drwxrwxrwx 1 ella ella 4096 Sep  6 10:43 .\n",
      "drwxrwxrwx 1 ella ella 4096 Sep  6 10:43 ..\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd mydir\n",
    "pwd\n",
    "ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Ellaa/Documents/Studium/Master Data Science/Introduction to Data Science/JupyterNotebooks\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Use the source\" by `man`-ning the unknown `command`\n",
    "\n",
    "By evaluating the next cell, you are using the `man`ual pages to find more about the command `ls`. You can learn more about any command called `command` by typing `man command` in the BASH shell.\n",
    "\n",
    "The output of the next cell with command `man ls` will look something like the following:\n",
    "\n",
    "```\n",
    "LS(1)                            User Commands                           LS(1)\n",
    "\n",
    "NAME\n",
    "       ls - list directory contents\n",
    "\n",
    "SYNOPSIS\n",
    "       ls [OPTION]... [FILE]...\n",
    "\n",
    "DESCRIPTION\n",
    "       List  information  about  the FILEs (the current directory by default).\n",
    "       Sort entries alphabetically if none of -cftuvSUX nor --sort  is  speci‐\n",
    "       fied.\n",
    "\n",
    "       Mandatory  arguments  to  long  options are mandatory for short options\n",
    "       too.\n",
    "\n",
    "       -a, --all\n",
    "              do not ignore entries starting with .\n",
    "\n",
    "       -A, --almost-all\n",
    "              do not list implied . and ..\n",
    "...\n",
    "...\n",
    "...\n",
    "   Exit status:\n",
    "       0      if OK,\n",
    "\n",
    "       1      if minor problems (e.g., cannot access subdirectory),\n",
    "\n",
    "       2      if serious trouble (e.g., cannot access command-line argument).\n",
    "\n",
    "AUTHOR\n",
    "       Written by Richard M. Stallman and David MacKenzie.\n",
    "\n",
    "REPORTING BUGS\n",
    "       GNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n",
    "       Report ls translation bugs to <http://translationproject.org/team/>\n",
    "\n",
    "COPYRIGHT\n",
    "       Copyright © 2017 Free Software Foundation, Inc.   License  GPLv3+:  GNU\n",
    "       GPL version 3 or later <http://gnu.org/licenses/gpl.html>.\n",
    "       This  is  free  software:  you  are free to change and redistribute it.\n",
    "       There is NO WARRANTY, to the extent permitted by law.\n",
    "\n",
    "SEE ALSO\n",
    "       Full documentation at: <http://www.gnu.org/software/coreutils/ls>\n",
    "       or available locally via: info '(coreutils) ls invocation'\n",
    "\n",
    "GNU coreutils 8.28               January 2018                            LS(1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS(1)                     User Commands                    LS(1)\n",
      "\n",
      "NAME\n",
      "       ls - list directory contents\n",
      "\n",
      "SYNOPSIS\n",
      "       ls [OPTION]... [FILE]...\n",
      "\n",
      "DESCRIPTION\n",
      "       List  information  about the FILEs (the current directory\n",
      "       by default).  Sort entries alphabetically if none of -cf‐\n",
      "       tuvSUX nor --sort is specified.\n",
      "\n",
      "       Mandatory  arguments  to  long  options are mandatory for\n",
      "       short options too.\n",
      "\n",
      "       -a, --all\n",
      "              do not ignore entries starting with .\n",
      "\n",
      "       -A, --almost-all\n",
      "              do not list implied . and ..\n",
      "\n",
      "       --author\n",
      "              with -l, print the author of each file\n",
      "\n",
      "       -b, --escape\n",
      "              print C-style escapes for nongraphic characters\n",
      "\n",
      "       --block-size=SIZE\n",
      "              with -l, scale sizes by SIZE when  printing  them;\n",
      "              e.g., '--block-size=M'; see SIZE format below\n",
      "\n",
      "       -B, --ignore-backups\n",
      "              do not list implied entries ending with ~\n",
      "\n",
      "       -c     with  -lt:  sort by, and show, ctime (time of last\n",
      "              modification of file status information); with -l:\n",
      "              show  ctime  and  sort by name; otherwise: sort by\n",
      "              ctime, newest first\n",
      "\n",
      "       -C     list entries by columns\n",
      "\n",
      "       --color[=WHEN]\n",
      "              colorize the output; WHEN can be 'always' (default\n",
      "              if omitted), 'auto', or 'never'; more info below\n",
      "\n",
      "       -d, --directory\n",
      "              list directories themselves, not their contents\n",
      "\n",
      "       -D, --dired\n",
      "              generate output designed for Emacs' dired mode\n",
      "\n",
      "       -f     do not sort, enable -aU, disable -ls --color\n",
      "\n",
      "       -F, --classify\n",
      "              append indicator (one of */=>@|) to entries\n",
      "\n",
      "       --file-type\n",
      "              likewise, except do not append '*'\n",
      "\n",
      "       --format=WORD\n",
      "              across -x, commas -m, horizontal -x, long -l, sin‐\n",
      "              gle-column -1, verbose -l, vertical -C\n",
      "\n",
      "       --full-time\n",
      "              like -l --time-style=full-iso\n",
      "\n",
      "       -g     like -l, but do not list owner\n",
      "\n",
      "       --group-directories-first\n",
      "              group directories before files;\n",
      "\n",
      "              can be augmented with a --sort option, but any use\n",
      "              of --sort=none (-U) disables grouping\n",
      "\n",
      "       -G, --no-group\n",
      "              in a long listing, don't print group names\n",
      "\n",
      "       -h, --human-readable\n",
      "              with -l and -s, print sizes like 1K 234M 2G etc.\n",
      "\n",
      "       --si   likewise, but use powers of 1000 not 1024\n",
      "\n",
      "       -H, --dereference-command-line\n",
      "              follow symbolic links listed on the command line\n",
      "\n",
      "       --dereference-command-line-symlink-to-dir\n",
      "              follow each command line symbolic link\n",
      "\n",
      "              that points to a directory\n",
      "\n",
      "       --hide=PATTERN\n",
      "              do not list implied entries matching shell PATTERN\n",
      "              (overridden by -a or -A)\n",
      "\n",
      "       --hyperlink[=WHEN]\n",
      "              hyperlink file names; WHEN can  be  'always'  (de‐\n",
      "              fault if omitted), 'auto', or 'never'\n",
      "\n",
      "       --indicator-style=WORD\n",
      "              append  indicator  with style WORD to entry names:\n",
      "              none    (default),    slash    (-p),     file-type\n",
      "              (--file-type), classify (-F)\n",
      "\n",
      "       -i, --inode\n",
      "              print the index number of each file\n",
      "\n",
      "       -I, --ignore=PATTERN\n",
      "              do not list implied entries matching shell PATTERN\n",
      "\n",
      "       -k, --kibibytes\n",
      "              default  to  1024-byte blocks for disk usage; used\n",
      "              only with -s and per directory totals\n",
      "\n",
      "       -l     use a long listing format\n",
      "\n",
      "       -L, --dereference\n",
      "              when showing file information for a symbolic link,\n",
      "              show  information for the file the link references\n",
      "              rather than for the link itself\n",
      "\n",
      "       -m     fill width with a comma separated list of entries\n",
      "\n",
      "       -n, --numeric-uid-gid\n",
      "              like -l, but list numeric user and group IDs\n",
      "\n",
      "       -N, --literal\n",
      "              print entry names without quoting\n",
      "\n",
      "       -o     like -l, but do not list group information\n",
      "\n",
      "       -p, --indicator-style=slash\n",
      "              append / indicator to directories\n",
      "\n",
      "       -q, --hide-control-chars\n",
      "              print ? instead of nongraphic characters\n",
      "\n",
      "       --show-control-chars\n",
      "              show nongraphic characters as-is (the default, un‐\n",
      "              less program is 'ls' and output is a terminal)\n",
      "\n",
      "       -Q, --quote-name\n",
      "              enclose entry names in double quotes\n",
      "\n",
      "       --quoting-style=WORD\n",
      "              use  quoting  style WORD for entry names: literal,\n",
      "              locale,   shell,    shell-always,    shell-escape,\n",
      "              shell-escape-always,  c,  escape  (overrides QUOT‐\n",
      "              ING_STYLE environment variable)\n",
      "\n",
      "       -r, --reverse\n",
      "              reverse order while sorting\n",
      "\n",
      "       -R, --recursive\n",
      "              list subdirectories recursively\n",
      "\n",
      "       -s, --size\n",
      "              print the allocated size of each file, in blocks\n",
      "\n",
      "       -S     sort by file size, largest first\n",
      "\n",
      "       --sort=WORD\n",
      "              sort by WORD instead  of  name:  none  (-U),  size\n",
      "              (-S), time (-t), version (-v), extension (-X)\n",
      "\n",
      "       --time=WORD\n",
      "              change  the  default  of using modification times;\n",
      "              access time (-u): atime, access, use; change  time\n",
      "              (-c): ctime, status; birth time: birth, creation;\n",
      "\n",
      "              with  -l, WORD determines which time to show; with\n",
      "              --sort=time, sort by WORD (newest first)\n",
      "\n",
      "       --time-style=TIME_STYLE\n",
      "              time/date format with -l; see TIME_STYLE below\n",
      "\n",
      "       -t     sort by time, newest first; see --time\n",
      "\n",
      "       -T, --tabsize=COLS\n",
      "              assume tab stops at each COLS instead of 8\n",
      "\n",
      "       -u     with -lt: sort by, and show, access time; with -l:\n",
      "              show access time and sort by name; otherwise: sort\n",
      "              by access time, newest first\n",
      "\n",
      "       -U     do not sort; list entries in directory order\n",
      "\n",
      "       -v     natural sort of (version) numbers within text\n",
      "\n",
      "       -w, --width=COLS\n",
      "              set output width to COLS.  0 means no limit\n",
      "\n",
      "       -x     list entries by lines instead of by columns\n",
      "\n",
      "       -X     sort alphabetically by entry extension\n",
      "\n",
      "       -Z, --context\n",
      "              print any security context of each file\n",
      "\n",
      "       -1     list one file per line.  Avoid '\\n' with -q or -b\n",
      "\n",
      "       --help display this help and exit\n",
      "\n",
      "       --version\n",
      "              output version information and exit\n",
      "\n",
      "       The SIZE argument is an integer and optional unit  (exam‐\n",
      "       ple:  10K is 10*1024).  Units are K,M,G,T,P,E,Z,Y (powers\n",
      "       of 1024) or KB,MB,... (powers of 1000).  Binary  prefixes\n",
      "       can be used, too: KiB=K, MiB=M, and so on.\n",
      "\n",
      "       The  TIME_STYLE  argument can be full-iso, long-iso, iso,\n",
      "       locale,  or  +FORMAT.   FORMAT  is  interpreted  like  in\n",
      "       date(1).  If FORMAT is FORMAT1<newline>FORMAT2, then FOR‐\n",
      "       MAT1 applies to non-recent files and  FORMAT2  to  recent\n",
      "       files.   TIME_STYLE  prefixed  with 'posix-' takes effect\n",
      "       only outside the POSIX locale.  Also the TIME_STYLE envi‐\n",
      "       ronment variable sets the default style to use.\n",
      "\n",
      "       Using color to distinguish file types is disabled both by\n",
      "       default and with --color=never.   With  --color=auto,  ls\n",
      "       emits  color codes only when standard output is connected\n",
      "       to a terminal.  The LS_COLORS  environment  variable  can\n",
      "       change  the  settings.   Use the dircolors command to set\n",
      "       it.\n",
      "\n",
      "   Exit status:\n",
      "       0      if OK,\n",
      "\n",
      "       1      if minor problems (e.g., cannot  access  subdirec‐\n",
      "              tory),\n",
      "\n",
      "       2      if  serious  trouble  (e.g.,  cannot  access  com‐\n",
      "              mand-line argument).\n",
      "\n",
      "AUTHOR\n",
      "       Written by Richard M. Stallman and David MacKenzie.\n",
      "\n",
      "REPORTING BUGS\n",
      "       GNU  coreutils  online  help:  <https://www.gnu.org/soft‐\n",
      "       ware/coreutils/>\n",
      "       Report  any  translation bugs to <https://translationpro‐\n",
      "       ject.org/team/>\n",
      "\n",
      "COPYRIGHT\n",
      "       Copyright © 2020 Free Software Foundation, Inc.   License\n",
      "       GPLv3+:  GNU  GPL version 3 or later <https://gnu.org/li‐\n",
      "       censes/gpl.html>.\n",
      "       This is free software: you are free to change and  redis‐\n",
      "       tribute  it.  There is NO WARRANTY, to the extent permit‐\n",
      "       ted by law.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SEE ALSO\n",
      "       Full  documentation   <https://www.gnu.org/software/core‐\n",
      "       utils/ls>\n",
      "       or  available  locally  via: info '(coreutils) ls invoca‐\n",
      "       tion'\n",
      "\n",
      "GNU coreutils 8.32       February 2022                    LS(1)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "## uncomment by removing '#' in the next line and try executing this cell\n",
    "man ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grabbing files from internet using curl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 29323  100 29323    0     0  22898      0  0:00:01  0:00:01 --:--:-- 22908\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd mydir\n",
    "curl -O http://lamastex.org/datasets/public/SOU/sou/20170228.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170228.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls mydir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald J. Trump \n",
      "\n",
      "February 28, 2017 \n",
      "Thank you very much. Mr. Speaker, Mr. Vice President, members of Congress, the first lady of the United States ... \n",
      "... and citizens of America, tonight, as we mark the conclusion of our celebration of Black History Month, we are reminded of our nation's path toward civil rights and the work that still remains to be done. \n",
      "Recent threats ... \n",
      "Recent threats targeting Jewish community centers and vandalism of Jewish cemeteries, as well as last week's shooting in Kansas City, remind us that while we may be a nation divided on policies, we are a country that stands united in condemning hate and evil in all of its very ugly forms. \n",
      "Each American generation passes the torch of truth, liberty and justice, in an unbroken chain all the way down to the present. That torch is now in our hands. And we will use it to light up the world. \n",
      "I am here tonight to deliver a message of unity and strength, and it is a message deeply delivered from my heart. A new chapter ... \n",
      "... of American greatness is now beginning. A new national pride is sweeping across our nation. And a new surge of optimism is placing impossible dreams firmly within our grasp. What we are witnessing today is the renewal of the American spirit. Our allies will find that America is once again ready to lead. \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd mydir/\n",
    "head 20170228.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To have more fun with all SOU addresses\n",
    "Do the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 3566k  100 3566k    0     0  78910      0  0:00:46  0:00:46 --:--:--  157k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir -p mydir # first create a directory called 'mydir'\n",
    "cd mydir # change into this mydir directory\n",
    "rm -f sou.tar.gz # remove any file in mydir called sou.tar.gz\n",
    "curl -O http://lamastex.org/datasets/public/SOU/sou.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Ellaa/Documents/Studium/Master Data Science/Introduction to Data Science/JupyterNotebooks\n",
      "total 3.6M\n",
      "-rwxrwxrwx 1 ella ella  29K Sep  6 10:47 20170228.txt\n",
      "-rwxrwxrwx 1 ella ella 3.5M Sep  6 10:52 sou.tar.gz\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pwd\n",
    "ls -lh mydir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sou/\n",
      "sou/18111105.txt\n",
      "sou/20040120.txt\n",
      "sou/19061203.txt\n",
      "sou/18411207.txt\n",
      "sou/19091207.txt\n",
      "sou/18701205.txt\n",
      "sou/19410106.txt\n",
      "sou/18571208.txt\n",
      "sou/18891203.txt\n",
      "sou/18341201.txt\n",
      "sou/19660112.txt\n",
      "sou/17981208.txt\n",
      "sou/19610130.txt\n",
      "sou/18140920.txt\n",
      "sou/18011208.txt\n",
      "sou/18811206.txt\n",
      "sou/18281202.txt\n",
      "sou/19840125.txt\n",
      "sou/18611203.txt\n",
      "sou/18731201.txt\n",
      "sou/19400103.txt\n",
      "sou/19630114.txt\n",
      "sou/19281204.txt\n",
      "sou/19221208.txt\n",
      "sou/19031207.txt\n",
      "sou/18681209.txt\n",
      "sou/18431206.txt\n",
      "sou/18861206.txt\n",
      "sou/19261207.txt\n",
      "sou/19271206.txt\n",
      "sou/19141208.txt\n",
      "sou/18791201.txt\n",
      "sou/19131202.txt\n",
      "sou/19041206.txt\n",
      "sou/18001111.txt\n",
      "sou/18041108.txt\n",
      "sou/20010227.txt\n",
      "sou/18621201.txt\n",
      "sou/19251208.txt\n",
      "sou/19700122.txt\n",
      "sou/19790125.txt\n",
      "sou/19870127.txt\n",
      "sou/20050202.txt\n",
      "sou/18331203.txt\n",
      "sou/17961207.txt\n",
      "sou/18021215.txt\n",
      "sou/18771203.txt\n",
      "sou/19890209.txt\n",
      "sou/18301206.txt\n",
      "sou/18121104.txt\n",
      "sou/19580109.txt\n",
      "sou/20110125.txt\n",
      "sou/19450106.txt\n",
      "sou/18031017.txt\n",
      "sou/19301202.txt\n",
      "sou/18661203.txt\n",
      "sou/19520109.txt\n",
      "sou/19620111.txt\n",
      "sou/18531205.txt\n",
      "sou/19610112.txt\n",
      "sou/19430107.txt\n",
      "sou/19960123.txt\n",
      "sou/17911025.txt\n",
      "sou/18211203.txt\n",
      "sou/18951207.txt\n",
      "sou/18901201.txt\n",
      "sou/18721202.txt\n",
      "sou/20140128.txt\n",
      "sou/18361205.txt\n",
      "sou/18101205.txt\n",
      "sou/18081108.txt\n",
      "sou/18961204.txt\n",
      "sou/18871206.txt\n",
      "sou/18781202.txt\n",
      "sou/19480107.txt\n",
      "sou/19001203.txt\n",
      "sou/18421206.txt\n",
      "sou/18241207.txt\n",
      "sou/18131207.txt\n",
      "sou/19500104.txt\n",
      "sou/20010920.txt\n",
      "sou/19940125.txt\n",
      "sou/19850206.txt\n",
      "sou/18541204.txt\n",
      "sou/17921106.txt\n",
      "sou/19800121.txt\n",
      "sou/19311208.txt\n",
      "sou/18461208.txt\n",
      "sou/19161205.txt\n",
      "sou/19121203.txt\n",
      "sou/19370106.txt\n",
      "sou/19151207.txt\n",
      "sou/19051205.txt\n",
      "sou/19021202.txt\n",
      "sou/18321204.txt\n",
      "sou/18671203.txt\n",
      "sou/18651204.txt\n",
      "sou/19510108.txt\n",
      "sou/18581206.txt\n",
      "sou/18161203.txt\n",
      "sou/19390104.txt\n",
      "sou/19321206.txt\n",
      "sou/18641206.txt\n",
      "sou/20070123.txt\n",
      "sou/18691206.txt\n",
      "sou/17991203.txt\n",
      "sou/18551231.txt\n",
      "sou/19440111.txt\n",
      "sou/19910129.txt\n",
      "sou/18921206.txt\n",
      "sou/18061202.txt\n",
      "sou/19470106.txt\n",
      "sou/19590109.txt\n",
      "sou/18151205.txt\n",
      "sou/18751207.txt\n",
      "sou/18981205.txt\n",
      "sou/20090224.txt\n",
      "sou/18071027.txt\n",
      "sou/18171212.txt\n",
      "sou/18821204.txt\n",
      "sou/19211206.txt\n",
      "sou/18371205.txt\n",
      "sou/19181202.txt\n",
      "sou/19720120.txt\n",
      "sou/18601203.txt\n",
      "sou/19530107.txt\n",
      "sou/18741207.txt\n",
      "sou/19460121.txt\n",
      "sou/19350104.txt\n",
      "sou/19201207.txt\n",
      "sou/18591219.txt\n",
      "sou/18221203.txt\n",
      "sou/19231206.txt\n",
      "sou/19730202.txt\n",
      "sou/19291203.txt\n",
      "sou/19820126.txt\n",
      "sou/20060131.txt\n",
      "sou/18501202.txt\n",
      "sou/17931203.txt\n",
      "sou/18711204.txt\n",
      "sou/18441203.txt\n",
      "sou/17900108.txt\n",
      "sou/18561202.txt\n",
      "sou/18381203.txt\n",
      "sou/19071203.txt\n",
      "sou/19570110.txt\n",
      "sou/19171204.txt\n",
      "sou/18181116.txt\n",
      "sou/19420106.txt\n",
      "sou/18201114.txt\n",
      "sou/20130212.txt\n",
      "sou/20030128.txt\n",
      "sou/19340103.txt\n",
      "sou/19970204.txt\n",
      "sou/19810116.txt\n",
      "sou/18841201.txt\n",
      "sou/19101206.txt\n",
      "sou/18351207.txt\n",
      "sou/17951208.txt\n",
      "sou/19530202.txt\n",
      "sou/18971206.txt\n",
      "sou/18231202.txt\n",
      "sou/18831204.txt\n",
      "sou/19490105.txt\n",
      "sou/18991205.txt\n",
      "sou/18391202.txt\n",
      "sou/18481205.txt\n",
      "sou/18631208.txt\n",
      "sou/19930217.txt\n",
      "sou/19111205.txt\n",
      "sou/19740130.txt\n",
      "sou/20160112.txt\n",
      "sou/19880125.txt\n",
      "sou/19690114.txt\n",
      "sou/19360103.txt\n",
      "sou/20120124.txt\n",
      "sou/18091129.txt\n",
      "sou/19680117.txt\n",
      "sou/18851208.txt\n",
      "sou/20100127.txt\n",
      "sou/19191202.txt\n",
      "sou/19670110.txt\n",
      "sou/18451202.txt\n",
      "sou/19241203.txt\n",
      "sou/20080128.txt\n",
      "sou/18291208.txt\n",
      "sou/19980127.txt\n",
      "sou/18401205.txt\n",
      "sou/18471207.txt\n",
      "sou/19540107.txt\n",
      "sou/18191207.txt\n",
      "sou/18801206.txt\n",
      "sou/18491204.txt\n",
      "sou/18881203.txt\n",
      "sou/19950124.txt\n",
      "sou/19380103.txt\n",
      "sou/18761205.txt\n",
      "sou/18931203.txt\n",
      "sou/18051203.txt\n",
      "sou/18271204.txt\n",
      "sou/19900131.txt\n",
      "sou/18941202.txt\n",
      "sou/20150120.txt\n",
      "sou/17941119.txt\n",
      "sou/18261205.txt\n",
      "sou/19710122.txt\n",
      "sou/17901208.txt\n",
      "sou/19081208.txt\n",
      "sou/19550106.txt\n",
      "sou/17971122.txt\n",
      "sou/19560105.txt\n",
      "sou/19640108.txt\n",
      "sou/20020129.txt\n",
      "sou/19920128.txt\n",
      "sou/18511202.txt\n",
      "sou/18311206.txt\n",
      "sou/19770112.txt\n",
      "sou/18521206.txt\n",
      "sou/19760119.txt\n",
      "sou/18251206.txt\n",
      "sou/19860204.txt\n",
      "sou/19830125.txt\n",
      "sou/19780119.txt\n",
      "sou/19650104.txt\n",
      "sou/19990119.txt\n",
      "sou/20000127.txt\n",
      "sou/19600107.txt\n",
      "sou/19011203.txt\n",
      "sou/19750115.txt\n",
      "sou/18911209.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd mydir \n",
    "tar zxvf sou.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the above two cells, you should have all the SOU (State of Union) addresses. By evaluating the next cell's `ls ...` command you should see the SOU files like the following:\n",
    "\n",
    "```\n",
    "total 11M\n",
    "-rw------- 1 raazesh raazesh 6.6K Feb 18  2016 17900108.txt\n",
    "-rw------- 1 raazesh raazesh 8.3K Feb 18  2016 17901208.txt\n",
    "-rw------- 1 raazesh raazesh  14K Feb 18  2016 17911025.txt\n",
    "...\n",
    "...\n",
    "...\n",
    "-rw------- 1 raazesh raazesh  39K Feb 18  2016 20140128.txt\n",
    "-rw------- 1 raazesh raazesh  38K Feb 18  2016 20150120.txt\n",
    "-rw------- 1 raazesh raazesh  31K Feb 18  2016 20160112.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 11M\n",
      "-rwxrwxrwx 1 ella ella 6.6K Feb 18  2016 17900108.txt\n",
      "-rwxrwxrwx 1 ella ella 8.3K Feb 18  2016 17901208.txt\n",
      "-rwxrwxrwx 1 ella ella  14K Feb 18  2016 17911025.txt\n",
      "-rwxrwxrwx 1 ella ella  13K Feb 18  2016 17921106.txt\n",
      "-rwxrwxrwx 1 ella ella  12K Feb 18  2016 17931203.txt\n",
      "-rwxrwxrwx 1 ella ella  18K Feb 18  2016 17941119.txt\n",
      "-rwxrwxrwx 1 ella ella  13K Feb 18  2016 17951208.txt\n",
      "-rwxrwxrwx 1 ella ella  17K Feb 18  2016 17961207.txt\n",
      "-rwxrwxrwx 1 ella ella  13K Feb 18  2016 17971122.txt\n",
      "-rwxrwxrwx 1 ella ella  14K Feb 18  2016 17981208.txt\n",
      "-rwxrwxrwx 1 ella ella 9.1K Feb 18  2016 17991203.txt\n",
      "-rwxrwxrwx 1 ella ella 8.2K Feb 18  2016 18001111.txt\n",
      "-rwxrwxrwx 1 ella ella  19K Feb 18  2016 18011208.txt\n",
      "-rwxrwxrwx 1 ella ella  13K Feb 18  2016 18021215.txt\n",
      "-rwxrwxrwx 1 ella ella  14K Feb 18  2016 18031017.txt\n",
      "-rwxrwxrwx 1 ella ella  13K Feb 18  2016 18041108.txt\n",
      "-rwxrwxrwx 1 ella ella  17K Feb 18  2016 18051203.txt\n",
      "-rwxrwxrwx 1 ella ella  17K Feb 18  2016 18061202.txt\n",
      "-rwxrwxrwx 1 ella ella  14K Feb 18  2016 18071027.txt\n",
      "-rwxrwxrwx 1 ella ella  16K Feb 18  2016 18081108.txt\n",
      "-rwxrwxrwx 1 ella ella  11K Feb 18  2016 18091129.txt\n",
      "-rwxrwxrwx 1 ella ella  15K Feb 18  2016 18101205.txt\n",
      "-rwxrwxrwx 1 ella ella  14K Feb 18  2016 18111105.txt\n",
      "-rwxrwxrwx 1 ella ella  20K Feb 18  2016 18121104.txt\n",
      "-rwxrwxrwx 1 ella ella  20K Feb 18  2016 18131207.txt\n",
      "-rwxrwxrwx 1 ella ella  13K Feb 18  2016 18140920.txt\n",
      "-rwxrwxrwx 1 ella ella  19K Feb 18  2016 18151205.txt\n",
      "-rwxrwxrwx 1 ella ella  20K Feb 18  2016 18161203.txt\n",
      "-rwxrwxrwx 1 ella ella  26K Feb 18  2016 18171212.txt\n",
      "-rwxrwxrwx 1 ella ella  26K Feb 18  2016 18181116.txt\n",
      "-rwxrwxrwx 1 ella ella  28K Feb 18  2016 18191207.txt\n",
      "-rwxrwxrwx 1 ella ella  21K Feb 18  2016 18201114.txt\n",
      "-rwxrwxrwx 1 ella ella  34K Feb 18  2016 18211203.txt\n",
      "-rwxrwxrwx 1 ella ella  28K Feb 18  2016 18221203.txt\n",
      "-rwxrwxrwx 1 ella ella  38K Feb 18  2016 18231202.txt\n",
      "-rwxrwxrwx 1 ella ella  49K Feb 18  2016 18241207.txt\n",
      "-rwxrwxrwx 1 ella ella  53K Feb 18  2016 18251206.txt\n",
      "-rwxrwxrwx 1 ella ella  46K Feb 18  2016 18261205.txt\n",
      "-rwxrwxrwx 1 ella ella  42K Feb 18  2016 18271204.txt\n",
      "-rwxrwxrwx 1 ella ella  44K Feb 18  2016 18281202.txt\n",
      "-rwxrwxrwx 1 ella ella  62K Feb 18  2016 18291208.txt\n",
      "-rwxrwxrwx 1 ella ella  89K Feb 18  2016 18301206.txt\n",
      "-rwxrwxrwx 1 ella ella  42K Feb 18  2016 18311206.txt\n",
      "-rwxrwxrwx 1 ella ella  46K Feb 18  2016 18321204.txt\n",
      "-rwxrwxrwx 1 ella ella  46K Feb 18  2016 18331203.txt\n",
      "-rwxrwxrwx 1 ella ella  79K Feb 18  2016 18341201.txt\n",
      "-rwxrwxrwx 1 ella ella  63K Feb 18  2016 18351207.txt\n",
      "-rwxrwxrwx 1 ella ella  72K Feb 18  2016 18361205.txt\n",
      "-rwxrwxrwx 1 ella ella  68K Feb 18  2016 18371205.txt\n",
      "-rwxrwxrwx 1 ella ella  69K Feb 18  2016 18381203.txt\n",
      "-rwxrwxrwx 1 ella ella  79K Feb 18  2016 18391202.txt\n",
      "-rwxrwxrwx 1 ella ella  54K Feb 18  2016 18401205.txt\n",
      "-rwxrwxrwx 1 ella ella  48K Feb 18  2016 18411207.txt\n",
      "-rwxrwxrwx 1 ella ella  49K Feb 18  2016 18421206.txt\n",
      "-rwxrwxrwx 1 ella ella  47K Feb 18  2016 18431206.txt\n",
      "-rwxrwxrwx 1 ella ella  55K Feb 18  2016 18441203.txt\n",
      "-rwxrwxrwx 1 ella ella  94K Feb 18  2016 18451202.txt\n",
      "-rwxrwxrwx 1 ella ella 106K Feb 18  2016 18461208.txt\n",
      "-rwxrwxrwx 1 ella ella  95K Feb 18  2016 18471207.txt\n",
      "-rwxrwxrwx 1 ella ella 125K Feb 18  2016 18481205.txt\n",
      "-rwxrwxrwx 1 ella ella  45K Feb 18  2016 18491204.txt\n",
      "-rwxrwxrwx 1 ella ella  49K Feb 18  2016 18501202.txt\n",
      "-rwxrwxrwx 1 ella ella  78K Feb 18  2016 18511202.txt\n",
      "-rwxrwxrwx 1 ella ella  59K Feb 18  2016 18521206.txt\n",
      "-rwxrwxrwx 1 ella ella  57K Feb 18  2016 18531205.txt\n",
      "-rwxrwxrwx 1 ella ella  61K Feb 18  2016 18541204.txt\n",
      "-rwxrwxrwx 1 ella ella  69K Feb 18  2016 18551231.txt\n",
      "-rwxrwxrwx 1 ella ella  63K Feb 18  2016 18561202.txt\n",
      "-rwxrwxrwx 1 ella ella  81K Feb 18  2016 18571208.txt\n",
      "-rwxrwxrwx 1 ella ella  97K Feb 18  2016 18581206.txt\n",
      "-rwxrwxrwx 1 ella ella  73K Feb 18  2016 18591219.txt\n",
      "-rwxrwxrwx 1 ella ella  83K Feb 18  2016 18601203.txt\n",
      "-rwxrwxrwx 1 ella ella  41K Feb 18  2016 18611203.txt\n",
      "-rwxrwxrwx 1 ella ella  49K Feb 18  2016 18621201.txt\n",
      "-rwxrwxrwx 1 ella ella  37K Feb 18  2016 18631208.txt\n",
      "-rwxrwxrwx 1 ella ella  36K Feb 18  2016 18641206.txt\n",
      "-rwxrwxrwx 1 ella ella  54K Feb 18  2016 18651204.txt\n",
      "-rwxrwxrwx 1 ella ella  44K Feb 18  2016 18661203.txt\n",
      "-rwxrwxrwx 1 ella ella  70K Feb 18  2016 18671203.txt\n",
      "-rwxrwxrwx 1 ella ella  60K Feb 18  2016 18681209.txt\n",
      "-rwxrwxrwx 1 ella ella  46K Feb 18  2016 18691206.txt\n",
      "-rwxrwxrwx 1 ella ella  51K Feb 18  2016 18701205.txt\n",
      "-rwxrwxrwx 1 ella ella  38K Feb 18  2016 18711204.txt\n",
      "-rwxrwxrwx 1 ella ella  24K Feb 18  2016 18721202.txt\n",
      "-rwxrwxrwx 1 ella ella  59K Feb 18  2016 18731201.txt\n",
      "-rwxrwxrwx 1 ella ella  54K Feb 18  2016 18741207.txt\n",
      "-rwxrwxrwx 1 ella ella  72K Feb 18  2016 18751207.txt\n",
      "-rwxrwxrwx 1 ella ella  40K Feb 18  2016 18761205.txt\n",
      "-rwxrwxrwx 1 ella ella  48K Feb 18  2016 18771203.txt\n",
      "-rwxrwxrwx 1 ella ella  48K Feb 18  2016 18781202.txt\n",
      "-rwxrwxrwx 1 ella ella  70K Feb 18  2016 18791201.txt\n",
      "-rwxrwxrwx 1 ella ella  41K Feb 18  2016 18801206.txt\n",
      "-rwxrwxrwx 1 ella ella  24K Feb 18  2016 18811206.txt\n",
      "-rwxrwxrwx 1 ella ella  19K Feb 18  2016 18821204.txt\n",
      "-rwxrwxrwx 1 ella ella  24K Feb 18  2016 18831204.txt\n",
      "-rwxrwxrwx 1 ella ella  54K Feb 18  2016 18841201.txt\n",
      "-rwxrwxrwx 1 ella ella 119K Feb 18  2016 18851208.txt\n",
      "-rwxrwxrwx 1 ella ella  91K Feb 18  2016 18861206.txt\n",
      "-rwxrwxrwx 1 ella ella  31K Feb 18  2016 18871206.txt\n",
      "-rwxrwxrwx 1 ella ella  55K Feb 18  2016 18881203.txt\n",
      "-rwxrwxrwx 1 ella ella  77K Feb 18  2016 18891203.txt\n",
      "-rwxrwxrwx 1 ella ella  68K Feb 18  2016 18901201.txt\n",
      "-rwxrwxrwx 1 ella ella  95K Feb 18  2016 18911209.txt\n",
      "-rwxrwxrwx 1 ella ella  80K Feb 18  2016 18921206.txt\n",
      "-rwxrwxrwx 1 ella ella  75K Feb 18  2016 18931203.txt\n",
      "-rwxrwxrwx 1 ella ella  96K Feb 18  2016 18941202.txt\n",
      "-rwxrwxrwx 1 ella ella  88K Feb 18  2016 18951207.txt\n",
      "-rwxrwxrwx 1 ella ella  93K Feb 18  2016 18961204.txt\n",
      "-rwxrwxrwx 1 ella ella  72K Feb 18  2016 18971206.txt\n",
      "-rwxrwxrwx 1 ella ella 121K Feb 18  2016 18981205.txt\n",
      "-rwxrwxrwx 1 ella ella  91K Feb 18  2016 18991205.txt\n",
      "-rwxrwxrwx 1 ella ella 116K Feb 18  2016 19001203.txt\n",
      "-rwxrwxrwx 1 ella ella 114K Feb 18  2016 19011203.txt\n",
      "-rwxrwxrwx 1 ella ella  57K Feb 18  2016 19021202.txt\n",
      "-rwxrwxrwx 1 ella ella  89K Feb 18  2016 19031207.txt\n",
      "-rwxrwxrwx 1 ella ella 102K Feb 18  2016 19041206.txt\n",
      "-rwxrwxrwx 1 ella ella 144K Feb 18  2016 19051205.txt\n",
      "-rwxrwxrwx 1 ella ella 135K Feb 18  2016 19061203.txt\n",
      "-rwxrwxrwx 1 ella ella 159K Feb 18  2016 19071203.txt\n",
      "-rwxrwxrwx 1 ella ella 113K Feb 18  2016 19081208.txt\n",
      "-rwxrwxrwx 1 ella ella  83K Feb 18  2016 19091207.txt\n",
      "-rwxrwxrwx 1 ella ella  42K Feb 18  2016 19101206.txt\n",
      "-rwxrwxrwx 1 ella ella 141K Feb 18  2016 19111205.txt\n",
      "-rwxrwxrwx 1 ella ella 150K Feb 18  2016 19121203.txt\n",
      "-rwxrwxrwx 1 ella ella  21K Feb 18  2016 19131202.txt\n",
      "-rwxrwxrwx 1 ella ella  25K Feb 18  2016 19141208.txt\n",
      "-rwxrwxrwx 1 ella ella  44K Feb 18  2016 19151207.txt\n",
      "-rwxrwxrwx 1 ella ella  13K Feb 18  2016 19161205.txt\n",
      "-rwxrwxrwx 1 ella ella  22K Feb 18  2016 19171204.txt\n",
      "-rwxrwxrwx 1 ella ella  31K Feb 18  2016 19181202.txt\n",
      "-rwxrwxrwx 1 ella ella  28K Feb 18  2016 19191202.txt\n",
      "-rwxrwxrwx 1 ella ella  16K Feb 18  2016 19201207.txt\n",
      "-rwxrwxrwx 1 ella ella  34K Feb 18  2016 19211206.txt\n",
      "-rwxrwxrwx 1 ella ella  35K Feb 18  2016 19221208.txt\n",
      "-rwxrwxrwx 1 ella ella  41K Feb 18  2016 19231206.txt\n",
      "-rwxrwxrwx 1 ella ella  42K Feb 18  2016 19241203.txt\n",
      "-rwxrwxrwx 1 ella ella  65K Feb 18  2016 19251208.txt\n",
      "-rwxrwxrwx 1 ella ella  62K Feb 18  2016 19261207.txt\n",
      "-rwxrwxrwx 1 ella ella  53K Feb 18  2016 19271206.txt\n",
      "-rwxrwxrwx 1 ella ella  49K Feb 18  2016 19281204.txt\n",
      "-rwxrwxrwx 1 ella ella  68K Feb 18  2016 19291203.txt\n",
      "-rwxrwxrwx 1 ella ella  29K Feb 18  2016 19301202.txt\n",
      "-rwxrwxrwx 1 ella ella  36K Feb 18  2016 19311208.txt\n",
      "-rwxrwxrwx 1 ella ella  26K Feb 18  2016 19321206.txt\n",
      "-rwxrwxrwx 1 ella ella  14K Feb 18  2016 19340103.txt\n",
      "-rwxrwxrwx 1 ella ella  21K Feb 18  2016 19350104.txt\n",
      "-rwxrwxrwx 1 ella ella  22K Feb 18  2016 19360103.txt\n",
      "-rwxrwxrwx 1 ella ella  17K Feb 18  2016 19370106.txt\n",
      "-rwxrwxrwx 1 ella ella  28K Feb 18  2016 19380103.txt\n",
      "-rwxrwxrwx 1 ella ella  23K Feb 18  2016 19390104.txt\n",
      "-rwxrwxrwx 1 ella ella  19K Feb 18  2016 19400103.txt\n",
      "-rwxrwxrwx 1 ella ella  19K Feb 18  2016 19410106.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 ella ella  20K Feb 18  2016 19420106.txt\n",
      "-rwxrwxrwx 1 ella ella  26K Feb 18  2016 19430107.txt\n",
      "-rwxrwxrwx 1 ella ella  22K Feb 18  2016 19440111.txt\n",
      "-rwxrwxrwx 1 ella ella  48K Feb 18  2016 19450106.txt\n",
      "-rwxrwxrwx 1 ella ella 171K Feb 18  2016 19460121.txt\n",
      "-rwxrwxrwx 1 ella ella  37K Feb 18  2016 19470106.txt\n",
      "-rwxrwxrwx 1 ella ella  30K Feb 18  2016 19480107.txt\n",
      "-rwxrwxrwx 1 ella ella  21K Feb 18  2016 19490105.txt\n",
      "-rwxrwxrwx 1 ella ella  30K Feb 18  2016 19500104.txt\n",
      "-rwxrwxrwx 1 ella ella  23K Feb 18  2016 19510108.txt\n",
      "-rwxrwxrwx 1 ella ella  30K Feb 18  2016 19520109.txt\n",
      "-rwxrwxrwx 1 ella ella  56K Feb 18  2016 19530107.txt\n",
      "-rwxrwxrwx 1 ella ella  43K Feb 18  2016 19530202.txt\n",
      "-rwxrwxrwx 1 ella ella  37K Feb 18  2016 19540107.txt\n",
      "-rwxrwxrwx 1 ella ella  46K Feb 18  2016 19550106.txt\n",
      "-rwxrwxrwx 1 ella ella  51K Feb 18  2016 19560105.txt\n",
      "-rwxrwxrwx 1 ella ella  26K Feb 18  2016 19570110.txt\n",
      "-rwxrwxrwx 1 ella ella  30K Feb 18  2016 19580109.txt\n",
      "-rwxrwxrwx 1 ella ella  30K Feb 18  2016 19590109.txt\n",
      "-rwxrwxrwx 1 ella ella  35K Feb 18  2016 19600107.txt\n",
      "-rwxrwxrwx 1 ella ella  40K Feb 18  2016 19610112.txt\n",
      "-rwxrwxrwx 1 ella ella  31K Feb 18  2016 19610130.txt\n",
      "-rwxrwxrwx 1 ella ella  39K Feb 18  2016 19620111.txt\n",
      "-rwxrwxrwx 1 ella ella  31K Feb 18  2016 19630114.txt\n",
      "-rwxrwxrwx 1 ella ella  19K Feb 18  2016 19640108.txt\n",
      "-rwxrwxrwx 1 ella ella  25K Feb 18  2016 19650104.txt\n",
      "-rwxrwxrwx 1 ella ella  30K Feb 18  2016 19660112.txt\n",
      "-rwxrwxrwx 1 ella ella  41K Feb 18  2016 19670110.txt\n",
      "-rwxrwxrwx 1 ella ella  29K Feb 18  2016 19680117.txt\n",
      "-rwxrwxrwx 1 ella ella  24K Feb 18  2016 19690114.txt\n",
      "-rwxrwxrwx 1 ella ella  25K Feb 18  2016 19700122.txt\n",
      "-rwxrwxrwx 1 ella ella  26K Feb 18  2016 19710122.txt\n",
      "-rwxrwxrwx 1 ella ella  23K Feb 18  2016 19720120.txt\n",
      "-rwxrwxrwx 1 ella ella 9.7K Feb 18  2016 19730202.txt\n",
      "-rwxrwxrwx 1 ella ella  29K Feb 18  2016 19740130.txt\n",
      "-rwxrwxrwx 1 ella ella  25K Feb 18  2016 19750115.txt\n",
      "-rwxrwxrwx 1 ella ella  30K Feb 18  2016 19760119.txt\n",
      "-rwxrwxrwx 1 ella ella  28K Feb 18  2016 19770112.txt\n",
      "-rwxrwxrwx 1 ella ella  26K Feb 18  2016 19780119.txt\n",
      "-rwxrwxrwx 1 ella ella  20K Feb 18  2016 19790125.txt\n",
      "-rwxrwxrwx 1 ella ella  20K Feb 18  2016 19800121.txt\n",
      "-rwxrwxrwx 1 ella ella 213K Feb 18  2016 19810116.txt\n",
      "-rwxrwxrwx 1 ella ella  31K Feb 18  2016 19820126.txt\n",
      "-rwxrwxrwx 1 ella ella  33K Feb 18  2016 19830125.txt\n",
      "-rwxrwxrwx 1 ella ella  30K Feb 18  2016 19840125.txt\n",
      "-rwxrwxrwx 1 ella ella  25K Feb 18  2016 19850206.txt\n",
      "-rwxrwxrwx 1 ella ella  20K Feb 18  2016 19860204.txt\n",
      "-rwxrwxrwx 1 ella ella  22K Feb 18  2016 19870127.txt\n",
      "-rwxrwxrwx 1 ella ella  28K Feb 18  2016 19880125.txt\n",
      "-rwxrwxrwx 1 ella ella  28K Feb 18  2016 19890209.txt\n",
      "-rwxrwxrwx 1 ella ella  21K Feb 18  2016 19900131.txt\n",
      "-rwxrwxrwx 1 ella ella  22K Feb 18  2016 19910129.txt\n",
      "-rwxrwxrwx 1 ella ella  27K Feb 18  2016 19920128.txt\n",
      "-rwxrwxrwx 1 ella ella  39K Feb 18  2016 19930217.txt\n",
      "-rwxrwxrwx 1 ella ella  42K Feb 18  2016 19940125.txt\n",
      "-rwxrwxrwx 1 ella ella  51K Feb 18  2016 19950124.txt\n",
      "-rwxrwxrwx 1 ella ella  36K Feb 18  2016 19960123.txt\n",
      "-rwxrwxrwx 1 ella ella  39K Feb 18  2016 19970204.txt\n",
      "-rwxrwxrwx 1 ella ella  42K Feb 18  2016 19980127.txt\n",
      "-rwxrwxrwx 1 ella ella  43K Feb 18  2016 19990119.txt\n",
      "-rwxrwxrwx 1 ella ella  44K Feb 18  2016 20000127.txt\n",
      "-rwxrwxrwx 1 ella ella  25K Feb 18  2016 20010227.txt\n",
      "-rwxrwxrwx 1 ella ella  17K Feb 18  2016 20010920.txt\n",
      "-rwxrwxrwx 1 ella ella  23K Feb 18  2016 20020129.txt\n",
      "-rwxrwxrwx 1 ella ella  32K Feb 18  2016 20030128.txt\n",
      "-rwxrwxrwx 1 ella ella  30K Feb 18  2016 20040120.txt\n",
      "-rwxrwxrwx 1 ella ella  30K Feb 18  2016 20050202.txt\n",
      "-rwxrwxrwx 1 ella ella  31K Feb 18  2016 20060131.txt\n",
      "-rwxrwxrwx 1 ella ella  32K Feb 18  2016 20070123.txt\n",
      "-rwxrwxrwx 1 ella ella  34K Feb 18  2016 20080128.txt\n",
      "-rwxrwxrwx 1 ella ella  33K Feb 18  2016 20090224.txt\n",
      "-rwxrwxrwx 1 ella ella  41K Feb 18  2016 20100127.txt\n",
      "-rwxrwxrwx 1 ella ella  39K Feb 18  2016 20110125.txt\n",
      "-rwxrwxrwx 1 ella ella  40K Feb 18  2016 20120124.txt\n",
      "-rwxrwxrwx 1 ella ella  37K Feb 18  2016 20130212.txt\n",
      "-rwxrwxrwx 1 ella ella  39K Feb 18  2016 20140128.txt\n",
      "-rwxrwxrwx 1 ella ella  38K Feb 18  2016 20150120.txt\n",
      "-rwxrwxrwx 1 ella ella  31K Feb 18  2016 20160112.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls -lh mydir/sou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington \n",
      "\n",
      "January 8, 1790 \n",
      "Fellow-Citizens of the Senate and House of Representatives: \n",
      "I embrace with great satisfaction the opportunity which now presents itself of congratulating you on the present favorable prospects of our public affairs. The recent accession of the important state of North Carolina to the Constitution of the United States (of which official information has been received), the rising credit and respectability of our country, the general and increasing good will toward the government of the Union, and the concord, peace, and plenty with which we are blessed are circumstances auspicious in an eminent degree to our national prosperity. \n",
      "In resuming your consultations for the general good you can not but derive encouragement from the reflection that the measures of the last session have been as satisfactory to your constituents as the novelty and difficulty of the work allowed you to hope. Still further to realize their expectations and to secure the blessings which a gracious Providence has placed within our reach will in the course of the present important session call for the cool and deliberate exertion of your patriotism, firmness, and wisdom. \n",
      "Among the many interesting objects which will engage your attention that of providing for the common defense will merit particular regard. To be prepared for war is one of the most effectual means of preserving peace. \n",
      "A free people ought not only to be armed, but disciplined; to which end a uniform and well-digested plan is requisite; and their safety and interest require that they should promote such manufactories as tend to render them independent of others for essential, particularly military, supplies. \n",
      "The proper establishment of the troops which may be deemed indispensable will be entitled to mature consideration. In the arrangements which may be made respecting it it will be of importance to conciliate the comfortable support of the officers and soldiers with a due regard to economy. \n",
      "There was reason to hope that the pacific measures adopted with regard to certain hostile tribes of Indians would have relieved the inhabitants of our southern and western frontiers from their depredations, but you will perceive from the information contained in the papers which I shall direct to be laid before you (comprehending a communication from the Commonwealth of Virginia) that we ought to be prepared to afford protection to those parts of the Union, and, if necessary, to punish aggressors. \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head mydir/sou/17900108.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama \n",
      "\n",
      "January 12, 2016 \n",
      "Mr. Speaker, Mr. Vice President, Members of Congress, my fellow Americans: \n",
      "Tonight marks the eighth year I've come here to report on the State of the Union. And for this final one, I'm going to try to make it shorter. I know some of you are antsy to get back to Iowa. \n",
      "I also understand that because it's an election season, expectations for what we'll achieve this year are low. Still, Mr. Speaker, I appreciate the constructive approach you and the other leaders took at the end of last year to pass a budget and make tax cuts permanent for working families. So I hope we can work together this year on bipartisan priorities like criminal justice reform, and helping people who are battling prescription drug abuse. We just might surprise the cynics again. \n",
      "But tonight, I want to go easy on the traditional list of proposals for the year ahead. Don't worry, I've got plenty, from helping students learn to write computer code to personalizing medical treatments for patients. And I'll keep pushing for progress on the work that still needs doing. Fixing a broken immigration system. Protecting our kids from gun violence. Equal pay for equal work, paid leave, raising the minimum wage. All these things still matter to hardworking families; they are still the right thing to do; and I will not let up until they get done. \n",
      "But for my final address to this chamber, I don't want to talk just about the next year. I want to focus on the next five years, ten years, and beyond. \n",
      "I want to focus on our future. \n",
      "We live in a time of extraordinary change, change that's reshaping the way we live, the way we work, our planet and our place in the world. It's change that promises amazing medical breakthroughs, but also economic disruptions that strain working families. It promises education for girls in the most remote villages, but also connects terrorists plotting an ocean away. It's change that can broaden opportunity, or widen inequality. And whether we like it or not, the pace of this change will only accelerate. \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head mydir/sou/20160112.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting analysis of the textual content of the *State of the Union (SoU)* addresses by all US presidents was done in:\n",
    "\n",
    "-   [Alix Rule, Jean-Philippe Cointet, and Peter S. Bearman, Lexical shifts, substantive changes, and continuity in State of the Union discourse, 1790–2014, PNAS 2015 112 (35) 10837-10844; doi:10.1073/pnas.1512221112](http://www.pnas.org/content/112/35/10837.full).\n",
    "\n",
    "![](images/F5.large.png)\n",
    "\n",
    "[Image source](http://www.pnas.org/content/112/35/10837/F5.large.jpg)\n",
    "\n",
    "[Fig. 5](http://www.pnas.org/content/112/35/10837.full). A river network captures the flow across history of US political discourse, as perceived by contemporaries. Time moves along the x axis. Clusters on semantic networks of 300 most frequent terms for each of 10 historical periods are displayed as vertical bars. Relations between clusters of adjacent periods are indexed by gray flows, whose density reflects their degree of connection. Streams that connect at any point in history may be considered to be part of the same system, indicated with a single color.\n",
    "\n",
    "**You** *will be able to carry out such analyses and/or critically reflect on the mathematical statistical assumptions made in such analyses, as you learn more during your programme of study after successfully completing this course.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How was the `sou.tgz` file created?\n",
    "\n",
    "If you are curious, read: [http://lamastex.org/datasets/public/SOU/README.md](http://lamastex.org/datasets/public/SOU/README.md).\n",
    "\n",
    "Briefly, this is how a website with SOU was scraped by Paul Brouwers and adapted by Raazesh Sainudiin. A data scientist, and more generally a researcher interested in making statistical inference from data that is readily available online in a particular format, is expected to be comfortable with such *web-scraping tasks* (which can be done in more gracious and robust ways using specialised Python libraries). Such tasks also known as *Extract-Load-Transform (ELT)* operations are often time-consuming, expensive and the necessary first step towards extracting value from data.\n",
    "\n",
    "### A bit of bash and lynx to achieve the scraping of the state of the union addresses of the US Presidents,\n",
    "#### by Paul Brouwers\n",
    "\n",
    "The code below is mainly there to show how the text content of each state of the union address was scraped from the following URL:\n",
    "\n",
    "* [http://stateoftheunion.onetwothree.net/texts/index.html](http://stateoftheunion.onetwothree.net/texts/index.html)\n",
    "\n",
    "Such data acquisition tasks is usually the first and cucial step in a data scientist's workflow.\n",
    "\n",
    "We have done this and put the data in the distributed file system for easy loading into our notebooks for further analysis.  This keeps us from having to install unix programs like `lynx`, `sed`, etc. that are needed in the shell script below.\n",
    "\n",
    "\n",
    "```\n",
    "for i in $(lynx --dump http://stateoftheunion.onetwothree.net/texts/index.html | grep texts | grep -v index | sed 's/.*http/http/') ; do lynx --dump $i | tail -n+13 | head -n-14 | sed 's/^\\s\\+//' | sed -e ':a;N;$!ba;s/\\(.\\)\\n/\\1 /g' -e 's/\\n/\\n\\n/' > $(echo $i | sed 's/.*\\([0-9]\\{8\\}\\).*/\\1/').txt ; done\n",
    "```\n",
    "\n",
    "Or in a more atomic form:\n",
    "\n",
    "```\n",
    "for i in $(lynx --dump http://stateoftheunion.onetwothree.net/texts/index.html \\\n",
    "\n",
    "        | grep texts \\\n",
    "\n",
    "        | grep -v index \\\n",
    "\n",
    "        | sed 's/.*http/http/')\n",
    "\n",
    "do \n",
    "\n",
    "        lynx --dump $i \\\n",
    "\n",
    "               | tail -n+13 \\\n",
    "\n",
    "               | head -n-14 \\\n",
    "\n",
    "               | sed 's/^\\s\\+//' \\\n",
    "\n",
    "               | sed -e ':a;N;$!ba;s/\\(.\\)\\n/\\1 /g' -e 's/\\n/\\n\\n/' \\\n",
    "\n",
    "               > $(echo $i | sed 's/.*\\([0-9]\\{8\\}\\).*/\\1/').txt\n",
    "\n",
    "done\n",
    "```\n",
    "\n",
    "If you have time and are curious how each of the components in the above pipeline via `|` operators work, try to read `man echo`,  `man sed`,  `man grep`,  `man head`,  `man tail`, and  `man lynx` or `lynx --help`. If a command like `lynx` is not in your system, then you can install it with some work (mostly googling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USAGE: lynx [options] [file]\n",
      "Options are:\n",
      "  -                 receive options and arguments from stdin\n",
      "  -accept_all_cookies \n",
      "                    accept cookies without prompting if Set-Cookie handling\n",
      "                    is on (off)\n",
      "  -anonymous        apply restrictions for anonymous account,\n",
      "                    see also -restrictions\n",
      "  -assume_charset=MIMEname\n",
      "                    charset for documents that don't specify it\n",
      "  -assume_local_charset=MIMEname\n",
      "                    charset assumed for local files\n",
      "  -assume_unrec_charset=MIMEname\n",
      "                    use this instead of unrecognized charsets\n",
      "  -auth=id:pw       authentication information for protected documents\n",
      "  -base             prepend a request URL comment and BASE tag to text/html\n",
      "                    outputs for -source dumps\n",
      "  -bibhost=URL      local bibp server (default http://bibhost/)\n",
      "  -book             use the bookmark page as the startfile (off)\n",
      "  -buried_news      toggles scanning of news articles for buried references (on)\n",
      "  -cache=NUMBER     NUMBER of documents cached in memory\n",
      "  -case             enable case sensitive user searching (off)\n",
      "  -center           toggle center alignment in HTML TABLE (off)\n",
      "  -cfg=FILENAME     specifies a lynx.cfg file other than the default\n",
      "  -child            exit on left-arrow in startfile, and disable save to disk\n",
      "  -child_relaxed    exit on left-arrow in startfile (allows save to disk)\n",
      "  -cmd_log=FILENAME log keystroke commands to the given file\n",
      "  -cmd_script=FILENAME\n",
      "                    read keystroke commands from the given file\n",
      "                    (see -cmd_log)\n",
      "  -collapse_br_tags toggles collapsing of BR tags (on)\n",
      "  -connect_timeout=N\n",
      "                    set the N-second connection timeout (18000)\n",
      "  -convert_to=FORMAT\n",
      "                    convert input, FORMAT is in MIME type notation\n",
      "                    (experimental)\n",
      "  -cookie_file=FILENAME\n",
      "                    specifies a file to use to read cookies\n",
      "  -cookie_save_file=FILENAME\n",
      "                    specifies a file to use to store cookies\n",
      "  -cookies          toggles handling of Set-Cookie headers (on)\n",
      "  -core             toggles forced core dumps on fatal errors (off)\n",
      "  -crawl            with -traversal, output each page to a file\n",
      "                    with -dump, format output as with -traversal, but to stdout\n",
      "  -curses_pads      uses curses pad feature to support left/right shifting (on)\n",
      "  -debug_partial    incremental display stages with MessageSecs delay (off)\n",
      "  -default_colors   use terminal default foreground/background colors (on)\n",
      "  -delay=NNN        set NNN-second delay at statusline message (0.000)\n",
      "  -display=DISPLAY  set the display variable for X exec'ed programs\n",
      "  -display_charset=MIMEname\n",
      "                    charset for the terminal output\n",
      "  -dont_wrap_pre    inhibit wrapping of text in <pre> when -dump'ing and\n",
      "                    -crawl'ing, mark wrapped lines in interactive session (off)\n",
      "  -dump             dump the first file to stdout and exit\n",
      "  -editor=EDITOR    enable edit mode with specified editor\n",
      "  -emacskeys        enable emacs-like key movement (off)\n",
      "  -enable_scrollback \n",
      "                    toggles compatibility with comm programs' scrollback\n",
      "                    keys (may be incompatible with some curses packages) (off)\n",
      "  -error_file=FILE  write the HTTP status code here\n",
      "  -exec             enable local program execution\n",
      "  -force_empty_hrefless_a \n",
      "                    force HREF-less 'A' elements to be empty (close them as\n",
      "                    soon as they are seen) (off)\n",
      "  -force_html       forces the first document to be interpreted as HTML (off)\n",
      "  -force_secure     toggles forcing of the secure flag for SSL cookies (off)\n",
      "  -forms_options    toggles forms-based vs old-style options menu (on)\n",
      "  -from             toggle transmission of From headers (on)\n",
      "  -ftp              disable ftp access (off)\n",
      "  -get_data         user data for get forms, read from stdin,\n",
      "                    terminated by '---' on a line\n",
      "  -head             send a HEAD request (off)\n",
      "  -help             print this usage message\n",
      "  -hiddenlinks=[option]\n",
      "                    hidden links: options are merge, listonly, or ignore\n",
      "  -historical       toggles use of '>' or '-->' as terminator for comments (off)\n",
      "  -homepage=URL     set homepage separate from start page\n",
      "  -html5_charsets   toggles use of HTML5 charset replacements (off)\n",
      "  -image_links      toggles inclusion of links for all images (off)\n",
      "  -index=URL        set the default index file to URL\n",
      "  -ismap            toggles inclusion of ISMAP links when client-side\n",
      "                    MAPs are present (off)\n",
      "  -justify          do justification of text (off)\n",
      "  -link=NUMBER      starting count for lnk#.dat files produced by -crawl (0)\n",
      "  -list_decoded     with -dump, forces it to decode URL-encoded links (on)\n",
      "  -list_inline      with -dump, forces it to show links inline with text (off)\n",
      "  -listonly         with -dump, forces it to show only the list of links (off)\n",
      "  -localhost        disable URLs that point to remote hosts (off)\n",
      "  -locexec          enable local program execution from local files only (off)\n",
      "  -lss=FILENAME     specifies a lynx.lss file other than the default\n",
      "  -mime_header      include mime headers and force source dump\n",
      "  -minimal          toggles minimal versus valid comment parsing (on)\n",
      "  -nested_tables    toggles nested-tables logic (off)\n",
      "  -newschunksize=NUMBER\n",
      "                    number of articles in chunked news listings\n",
      "  -newsmaxchunk=NUMBER\n",
      "                    maximum news articles in listings before chunking\n",
      "  -nobold           disable bold video-attribute\n",
      "  -nobrowse         disable directory browsing\n",
      "  -nocc             disable Cc: prompts for self copies of mailings (off)\n",
      "  -nocolor          turn off color support\n",
      "  -noexec           disable local program execution (DEFAULT) (on)\n",
      "  -nofilereferer    disable transmission of Referer headers for file URLs (on)\n",
      "  -nolist           disable the link list feature in dumps (off)\n",
      "  -nolog            disable mailing of error messages to document owners (on)\n",
      "  -nomargins        disable the right/left margins in the default\n",
      "                    style-sheet (off)\n",
      "  -nomore           disable -more- string in statusline messages\n",
      "  -nonrestarting_sigwinch \n",
      "                    make window size change handler non-restarting (off)\n",
      "  -nonumbers        disable the link/form numbering feature in dumps (off)\n",
      "  -nopause          disable forced pauses for statusline messages\n",
      "  -noprint          disable some print functions, like -restrictions=print (off)\n",
      "  -noredir          don't follow Location: redirection (off)\n",
      "  -noreferer        disable transmission of Referer headers (off)\n",
      "  -noreverse        disable reverse video-attribute\n",
      "  -nostatus         disable the miscellaneous information messages (off)\n",
      "  -notitle          disable the title at the top of each page (off)\n",
      "  -nounderline      disable underline video-attribute\n",
      "  -nozap=DURATION (\"initially\" or \"full\") disable checks for 'z' key\n",
      "  -number_fields    force numbering of links as well as form input fields (off)\n",
      "  -number_links     force numbering of links (off)\n",
      "  -partial          toggles display partial pages while downloading (on)\n",
      "  -partial_thres    [=NUMBER]\n",
      "                    number of lines to render before repainting display\n",
      "                    with partial-display logic (-1)\n",
      "  -passive_ftp      toggles passive ftp connection (on)\n",
      "  -pauth=id:pw      authentication information for protected proxy server\n",
      "  -popup            toggles handling of single-choice SELECT options via\n",
      "                    popup windows or as lists of radio buttons (off)\n",
      "  -post_data        user data for post forms, read from stdin,\n",
      "                    terminated by '---' on a line\n",
      "  -preparsed        show parsed text/html with -source and in source view\n",
      "                    to visualize how lynx behaves with invalid HTML (off)\n",
      "  -prettysrc        do syntax highlighting and hyperlink handling in source\n",
      "                    view (off)\n",
      "  -print            enable print functions (DEFAULT), opposite of -noprint (on)\n",
      "  -pseudo_inlines   toggles pseudo-ALTs for inlines with no ALT string (on)\n",
      "  -raw              toggles default setting of 8-bit character translations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    or CJK mode for the startup character set (off)\n",
      "  -realm            restricts access to URLs in the starting realm (off)\n",
      "  -read_timeout=N   set the N-second read-timeout (18000)\n",
      "  -reload           flushes the cache on a proxy server\n",
      "                    (only the first document affected) (off)\n",
      "  -restrictions=[options]\n",
      "                    use -restrictions to see list\n",
      "  -resubmit_posts   toggles forced resubmissions (no-cache) of forms with\n",
      "                    method POST when the documents they returned are sought\n",
      "                    with the PREV_DOC command or from the History List (off)\n",
      "  -rlogin           disable rlogins (off)\n",
      "  -scrollbar        toggles showing scrollbar (off)\n",
      "  -scrollbar_arrow  toggles showing arrows at ends of the scrollbar (on)\n",
      "  -selective        require .www_browsable files to browse directories\n",
      "  -session=FILENAME resumes from specified file on startup and\n",
      "                    saves session to that file on exit\n",
      "  -sessionin=FILENAME\n",
      "                    resumes session from specified file\n",
      "  -sessionout=FILENAME\n",
      "                    saves session to specified file\n",
      "  -short_url        enables examination of beginning and end of long URL in\n",
      "                    status line (off)\n",
      "  -show_cfg         Show `LYNX.CFG' setting (off)\n",
      "  -show_cursor      toggles hiding of the cursor in the lower right corner (on)\n",
      "  -show_rate        toggles display of transfer rate (on)\n",
      "  -socks5_proxy=URL (via which) SOCKS5 proxy to connect (unrelated to -nosocks!)\n",
      "  -soft_dquotes     toggles emulation of the old Netscape and Mosaic\n",
      "                    bug which treated '>' as a co-terminator for\n",
      "                    double-quotes and tags (off)\n",
      "  -source           dump the source of the first file to stdout and exit\n",
      "  -stack_dump       disable SIGINT cleanup handler (off)\n",
      "  -startfile_ok     allow non-http startfile and homepage with -validate (off)\n",
      "  -stderr           write warning messages to standard error when -dump\n",
      "                    or -source is used (off)\n",
      "  -stdin            read startfile from standard input (off)\n",
      "  -syslog=text      information for syslog call\n",
      "  -syslog_urls      log requested URLs with syslog (off)\n",
      "  -tagsoup          use TagSoup rather than SortaSGML parser (off)\n",
      "  -telnet           disable telnets (off)\n",
      "  -term=TERM        set terminal type to TERM\n",
      "  -tlog             toggles use of a Lynx Trace Log for the current\n",
      "                    session (on)\n",
      "  -tna              turn on \"Textfields Need Activation\" mode (off)\n",
      "  -trace            turns on Lynx trace mode (off)\n",
      "  -trace_mask       customize Lynx trace mode (0)\n",
      "  -traversal        traverse all http links derived from startfile\n",
      "  -trim_blank_lines \n",
      "                    toggle trimming of leading/trailing/collapsed-br blank lines (on)\n",
      "  -trim_input_fields \n",
      "                    trim input text/textarea fields in forms (off)\n",
      "  -underline_links  toggles use of underline/bold attribute for links (off)\n",
      "  -underscore       toggles use of _underline_ format in dumps (off)\n",
      "  -unique_urls      toggles use of unique-urls setting for -dump and -listonly options (off)\n",
      "  -update_term_title enables updating the title of terminal emulators (off)\n",
      "  -use_mouse        turn on mouse support (off)\n",
      "  -useragent=Name   set alternate Lynx User-Agent header\n",
      "  -validate         accept only http URLs (meant for validation)\n",
      "                    implies more restrictions than -anonymous, but\n",
      "                    goto is allowed for http and https (off)\n",
      "  -verbose          toggles [LINK], [IMAGE] and [INLINE] comments\n",
      "                    with filenames of these images (on)\n",
      "  -version          print Lynx version information\n",
      "  -vikeys           enable vi-like key movement (off)\n",
      "  -width=NUMBER     screen width for formatting of dumps (default is 80)\n",
      "  -with_backspaces  emit backspaces in output if -dumping or -crawling\n",
      "                    (like 'man' does) (off)\n",
      "  -xhtml_parsing    enable XHTML 1.0 parsing (off)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "## uncomment by removing '#' in the next line and try executing this cell by pressing Ctrl-Enter to see if lynx is installed\n",
    "lynx --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So using `lynx` is not that difficult. Suppose you want to dump the contents of [https://lamastex.github.io/research/#available-student-projects](https://lamastex.github.io/research/#available-student-projects) to `stdout` or standard out, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   #[1]LaMaStEx Feed\n",
      "\n",
      "   [2]LaMaStEx\n",
      "     * [3]About\n",
      "     * [4]Contact\n",
      "     * [5]Research\n",
      "     * [6]CV\n",
      "     * [7]Publications\n",
      "     * [8]Software\n",
      "     * [9]Courses\n",
      "     * [10]Talks\n",
      "     * [11]Students\n",
      "\n",
      "   (BUTTON)\n",
      "\n",
      "Research and Available Student Projects\n",
      "\n",
      "   At the interface of computing, mathematics and statistics.\n",
      "\n",
      "   Raazesh Sainudiin\n",
      "\n",
      "Raazesh Sainudiin\n",
      "\n",
      "   I work at the interface of computing, mathematics and statistics to\n",
      "   solve real-world problems through custom-built mathematical and\n",
      "   statistical models.\n",
      "   (BUTTON) Follow\n",
      "     * Uppsala, Sweden\n",
      "     * Email\n",
      "     * [12]LinkedIn\n",
      "     * [13]GitHub\n",
      "     * [14]YouTube\n",
      "\n",
      "   [ ] Toggle Menu\n",
      "     * [15]LaMaStEx\n",
      "          + [16]About\n",
      "          + [17]Contact\n",
      "     * [18]Research\n",
      "          + [19]CV\n",
      "          + [20]Publications\n",
      "          + [21]Software\n",
      "          + [22]Talks\n",
      "          + [23]Students\n",
      "     * [24]Courses\n",
      "          + [25]Scalable Data Science\n",
      "\n",
      "On This Page\n",
      "\n",
      "     * [26]Research Overview\n",
      "     * [27]Available Student Projects\n",
      "          + [28]GDELT Project\n",
      "          + [29]Financial Streams Project\n",
      "          + [30]Meme Evolution in Twitterverse Project\n",
      "          + [31]Scalable Density Estimators Project\n",
      "          + [32]Notebook-Format-Agnostic Data Engineering Science Project\n",
      "          + [33]Other Projects\n",
      "\n",
      "Research Overview\n",
      "\n",
      "   Research at LaMaStEx is at the interdisciplinary interface of\n",
      "   computing, mathematics and statistics. We use computer arithmetic and\n",
      "   combinatorial data-structures through custom-built mathematical and\n",
      "   statistical models to rigorously solve numerical optimization and\n",
      "   simulation problems that arise in statistical decision-making from\n",
      "   real-world data.\n",
      "     * [34]Curriculum Vitae for a field-specific picture\n",
      "     * [35]The full list of peer-reviewed publications\n",
      "     * [36]Research students supervised at LaMaStEx\n",
      "     * [37]Mathematical Statistical Software\n",
      "\n",
      "Available Student Projects\n",
      "\n",
      "   Current student research projects involve a mixture of skills from\n",
      "   mathematics, computer science, statistics, data engineering and data\n",
      "   science. Therefore, finding a suitable project of mutual interest given\n",
      "   the acquirable skillset requires some discussions.\n",
      "\n",
      "   Here is a list of student project proposals of current interest. It is\n",
      "   meant as a guide for a student or a small group of students who are\n",
      "   interested in being guided by Raazesh Sainudiin for their individual or\n",
      "   group project in a course of study or research at Uppsala University.\n",
      "   These projects may help student(s) decide if they would like to do a\n",
      "   Bachelor’s thesis, Masters thesis (exjobb), or pursue other research\n",
      "   and development possibilities with Raazesh Sainudiin at the Department\n",
      "   of Mathematics, Uppsala University.\n",
      "\n",
      "   The exact nature and pathway towards a project will depend on your\n",
      "   current knowledge and skills and your willingness to acquire them. A\n",
      "   subset of the following skills is needed for each project. We can make\n",
      "   a self-study pathway specifically for you and the project.\n",
      "    1. Software Skills: docker, docker-compose, git, sbt, maven, c/g/make,\n",
      "       etc.\n",
      "    2. Programming Languages: Python, Scala, Haskell, C, C++, R, Rust,\n",
      "       Javascript,\n",
      "    3. Mathematical and Statistical Background: Probability, Graphs,\n",
      "       Algebra, Analysis, Optimization, ML models, etc.\n",
      "    4. Computing Skills: system administration, distibuted computing,\n",
      "       high-performance computing, etc.\n",
      "\n",
      "GDELT Project\n",
      "\n",
      "   The [38]GDELT project has many possibilities depending on your\n",
      "   interests and abilities.\n",
      "     * Applied Digital Humanities: Learn basic SQL and GQL to be able to\n",
      "       work in a delta lake house with GDELT data with the aim of\n",
      "       providing useful insights to researchers in [39]digital humanities.\n",
      "       See the following libraries to appreciate some of the\n",
      "       possibilities:\n",
      "          + First familiarize with [40]spark-gdelt and see some\n",
      "            [41]example analytics.\n",
      "          + GDELT PSL project: Learn [42]PSL and apply it to GDELT data\n",
      "            extract.\n",
      "          + GDELT GQL project: Learn Graph Query Language and apply it to\n",
      "            GDELT data to provide insights for digital humanities\n",
      "            researchers (may want to work closely with such researchers).\n",
      "          + GDELT Interact project: Develop an interactive UX for an\n",
      "            analyst interested in interacting with details of SQL and GQL\n",
      "            queries. This project requires experience in full-stack\n",
      "            development in a team of 3 to 4 students.\n",
      "          + Other projects based on the GDELT data.\n",
      "\n",
      "Financial Streams Project\n",
      "\n",
      "   Using multiple time series of financial stock market data, develop\n",
      "   further from [43]trend-calculus streams of them. The development can be\n",
      "   along predictive fronts using appropriate ML models or involve\n",
      "   estimators by extending [44]these examples. The general idea would be\n",
      "   to identify recurrent multivariate signals of interest in the trends of\n",
      "   historical financial data.\n",
      "\n",
      "Meme Evolution in Twitterverse Project\n",
      "\n",
      "   Using twitter experiments with [45]Project MEP there are many\n",
      "   posibilities here. The projects can focus\n",
      "     * purely on the data engineering side involving [46]terraform.io by\n",
      "       extending the infrastructure as code work started [47]here, or\n",
      "     * on analytic and mathematical modeling side comparing the\n",
      "       [48]polarised state of the Swedish political twitterverse from last\n",
      "       Swedish election to a new collection that can be started this\n",
      "       Semester, or\n",
      "     * refine and extend the interactive visual investigations developed\n",
      "       in [49]twitterVisualizations or\n",
      "     * extend distributed algorithms to characterize the evolution of\n",
      "       ideological networks in the Twitterverse (see [50]this statistical\n",
      "       application for example).\n",
      "\n",
      "Scalable Density Estimators Project\n",
      "\n",
      "   This project is suitable for a student of mathematics with skills in\n",
      "   functional programming over a distributed computing architecture (or\n",
      "   one who can self-learn such skills). To appreciate the starting point\n",
      "   of this advanced project read [51]this paper and try out [52]this Scala\n",
      "   Spark library with a view towards implementing the algorithms in\n",
      "   [53]this paper using the Scala Spark library.\n",
      "\n",
      "Notebook-Format-Agnostic Data Engineering Science Project\n",
      "\n",
      "   This is for a small group of 2-4 engineering students who collectively\n",
      "   have skills spanning Haskell to be able to use [54]pinot,\n",
      "   docker-compose or Kubernetes to provision [55]Apache Spark clusters in\n",
      "   its modern ecosystem with [56]zeppelin and [57]jupyter notebooks\n",
      "   servers. The objective of this project is to allow for\n",
      "   notebook-format-agnostic data science and analytics. Cloud computing\n",
      "   across onpremise and public clouds is a pre-requiste.\n",
      "\n",
      "Other Projects\n",
      "\n",
      "   There are several other project possibilities. However, this depends on\n",
      "   current research interests and coming up with a reasonable plan. Please\n",
      "   go through [58]Selected Publications by Field to propose other project\n",
      "   ideas spanning across population genetics, computer-aided proofs,\n",
      "   mobility science, etc.\n",
      "\n",
      "Share on\n",
      "\n",
      "   [59]Twitter [60]Facebook [61]Google+ [62]LinkedIn\n",
      "\n",
      "     * Follow:\n",
      "     * [63]GitHub\n",
      "     * [64]Feed\n",
      "\n",
      "   © 2023 Raazesh Sainudiin. Powered by [65]Jekyll & [66]Minimal Mistakes.\n",
      "\n",
      "References\n",
      "\n",
      "   Visible links:\n",
      "   1. https://lamastex.github.io/feed.xml\n",
      "   2. https://lamastex.github.io/\n",
      "   3. https://lamastex.github.io/about/\n",
      "   4. https://lamastex.github.io/contact/\n",
      "   5. https://lamastex.github.io/research/\n",
      "   6. https://lamastex.github.io/cv/\n",
      "   7. https://lamastex.github.io/publications/\n",
      "   8. https://lamastex.github.io/software/\n",
      "   9. https://lamastex.github.io/courses/\n",
      "  10. https://lamastex.github.io/talks/\n",
      "  11. https://lamastex.github.io/students/\n",
      "  12. https://www.linkedin.com/in/raazesh-sainudiin-45955845\n",
      "  13. https://github.com/lamastex\n",
      "  14. https://www.youtube.com/user/raazeshsainudiin\n",
      "  15. https://lamastex.github.io/\n",
      "  16. https://lamastex.github.io/about/\n",
      "  17. https://lamastex.github.io/contact/\n",
      "  18. https://lamastex.github.io/research/\n",
      "  19. https://lamastex.github.io/cv/\n",
      "  20. https://lamastex.github.io/publications/\n",
      "  21. https://lamastex.github.io/software/\n",
      "  22. https://lamastex.github.io/talks/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  23. https://lamastex.github.io/students/\n",
      "  24. https://lamastex.github.io/courses/\n",
      "  25. https://lamastex.github.io/scalable-data-science\n",
      "  26. https://lamastex.github.io/research/#research-overview\n",
      "  27. https://lamastex.github.io/research/#available-student-projects\n",
      "  28. https://lamastex.github.io/research/#gdelt-project\n",
      "  29. https://lamastex.github.io/research/#financial-streams-project\n",
      "  30. https://lamastex.github.io/research/#meme-evolution-in-twitterverse-project\n",
      "  31. https://lamastex.github.io/research/#scalable-density-estimators-project\n",
      "  32. https://lamastex.github.io/research/#notebook-format-agnostic-data-engineering-science-project\n",
      "  33. https://lamastex.github.io/research/#other-projects\n",
      "  34. https://lamastex.github.io/cv/\n",
      "  35. https://lamastex.github.io/publications/\n",
      "  36. https://lamastex.github.io/students/\n",
      "  37. https://lamastex.github.io/software/\n",
      "  38. https://www.gdeltproject.org/\n",
      "  39. https://www.abm.uu.se/cdhu-eng\n",
      "  40. https://github.com/lamastex/spark-gdelt\n",
      "  41. https://github.com/lamastex/spark-gdelt-examples\n",
      "  42. https://psl.linqs.org/\n",
      "  43. https://github.com/lamastex/spark-trend-calculus\n",
      "  44. https://github.com/lamastex/spark-trend-calculus-examples\n",
      "  45. https://github.com/lamastex/mep\n",
      "  46. https://www.terraform.io/\n",
      "  47. https://github.com/lamastex/mep/tree/main/infra/tf\n",
      "  48. http://lamastex.org/preprints/20190830_PolarisedMEPSverige.pdf\n",
      "  49. https://github.com/lamastex/twitterVisualizations\n",
      "  50. https://doi.org/10.1007/s13278-019-0567-9\n",
      "  51. https://arxiv.org/abs/2012.14847\n",
      "  52. https://gitlab.com/tilowiklund/distributed-histogram-trees\n",
      "  53. http://interval.louisiana.edu/reliable-computing-journal/volume-16/reliable-computing-16-pp-252-282.pdf\n",
      "  54. https://gitlab.com/tilowiklund/pinot/\n",
      "  55. https://spark.apache.org/\n",
      "  56. https://zeppelin.apache.org/\n",
      "  57. https://jupyterhub.readthedocs.io/en/stable/index.html\n",
      "  58. https://lamastex.github.io/cv/#selected-publications-by-field\n",
      "  59. https://twitter.com/intent/tweet?text=Research and Available Student Projects https://lamastex.github.io/research/\n",
      "  60. https://www.facebook.com/sharer/sharer.php?u=https://lamastex.github.io/research/\n",
      "  61. https://plus.google.com/share?url=https://lamastex.github.io/research/\n",
      "  62. https://www.linkedin.com/shareArticle?mini=true&url=https://lamastex.github.io/research/\n",
      "  63. http://github.com/lamastex\n",
      "  64. https://lamastex.github.io/feed.xml\n",
      "  65. http://jekyllrb.com/\n",
      "  66. https://mademistakes.com/work/minimal-mistakes-jekyll-theme/\n",
      "\n",
      "   Hidden links:\n",
      "  68. mailto:raazesh.sainudiin@gmail.com\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "## uncomment by removing '#' in the next line and try executing this cell if lynx is installed\n",
    "lynx --dump https://lamastex.github.io/research/#available-student-projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you had fun with BASH! Now let us put BASH to use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "lx_course_instance": "2023",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
