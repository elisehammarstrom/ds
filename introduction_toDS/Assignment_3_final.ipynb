{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Assignment 3 for Course 1MS041\n",
    "Make         sure you pass the `# ... Test` cells and\n",
    " submit your solution notebook in the corresponding assignment on the course website. You can submit multiple times before the deadline         and your highest score will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 1\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "Consider the data `X` and `y`, in the cell below. `X` denotes $20$ points in $\\mathbb{R}^2$ and `y` corresponds to the labels for these points, i.e. it is a classification problem.\n",
    "\n",
    "1. [3p] Implement the function `perceptron` by filling in `XXX`.\n",
    "2. [2p] Use your implemented `perceptron` function to compute a vector (numpy array) $\\hat w$ with shape `(3,1)` such that \n",
    "$$\n",
    "    (\\hat w \\cdot \\hat x_i) l_i > 0, \\quad \\forall i=1,\\ldots,20\n",
    "$$\n",
    "put your answer in `hat_w` below (the last dimension is the bias dimension, i.e. the added dimension we used to derive the perceptron)\n",
    "\n",
    "3. [3p] Use the vector $\\hat w$ that you just found and compute $r = \\max_i |x_i|$ (put your result in `r`), finally use this to give an upper bound to the number of iterations needed for the perceptron algorithm to converge on this dataset, see chapter 8 in the ITDS notes. Put the result in `iteration_bound`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "X = np.array([[0.14774693918368506,0.8537253157278155],[-0.1755517430286779,0.8979710703337818],[0.5227216475286975,0.7448281947022451],[-0.5071170511153492,0.8002027400836075],[-0.39436968212400453,1.0177689414422981],[-0.3983065780966649,1.0443663197782966],[-0.08652771617599643,0.48036820824519255],[0.15352541170101042,0.6820807981911706],[-0.3303348532791869,1.120673883903539],[-0.2656220857139274,0.8526638282828739],[0.7259603693529442,0.25428467532034965],[0.4577253912481767,-0.2358809079980879],[0.9722462145222105,0.13128550836973255],[0.4089349951770505,-0.09503914544452634],[0.9718156747909192,0.3524307824261209],[1.2009353774940565,-0.25004126389987974],[1.271791635779178,-0.07571928320750206],[0.36784476124502913,-0.23743021661715671],[0.8918396050420891,-0.1029336332277948],[0.4501578013678095,-0.13188266835015783]])+np.array([10,0]).reshape(1,-1)\n",
    "y = np.array([1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "import numpy as np\n",
    "def perceptron(X_in,labels,max_iter=1000):\n",
    "    '''Runs the perceptron algorithm on X_in, labels, and does a maximum of max_iter iterations'''\n",
    "    #w = XXX\n",
    "    # Dont forget the addition of the extra dimension to encode the\n",
    "    # bias in the perceptron, i.e. adding the extra dimension with value 1\n",
    "    \n",
    "    # Add a bias term to the input data\n",
    "    \n",
    "    X = X_in\n",
    "    y = labels\n",
    "    n_steps = max_iter\n",
    "    \n",
    "    X = np.c_[X, np.ones(X.shape[0])]\n",
    "    \n",
    "    # Initialize weights to zeros\n",
    "    W = np.zeros(X.shape[1])\n",
    "\n",
    "    # Main perceptron algorithm\n",
    "    for _ in range(n_steps):\n",
    "        misclassified = False\n",
    "        for i in range(X.shape[0]):\n",
    "            if np.dot(X[i], W) * y[i] <= 0:\n",
    "                W += X[i] * y[i]\n",
    "                misclassified = True\n",
    "\n",
    "        # If no misclassifications are found, the algorithm has converged\n",
    "        if not misclassified:\n",
    "            break\n",
    "    \n",
    "    w = W.reshape(-1,1)\n",
    "    \n",
    "    return w #Make sure that w has the shape described in the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "import numpy as np\n",
    "X = np.array([[0.14774693918368506,0.8537253157278155],[-0.1755517430286779,0.8979710703337818],[0.5227216475286975,0.7448281947022451],[-0.5071170511153492,0.8002027400836075],[-0.39436968212400453,1.0177689414422981],[-0.3983065780966649,1.0443663197782966],[-0.08652771617599643,0.48036820824519255],[0.15352541170101042,0.6820807981911706],[-0.3303348532791869,1.120673883903539],[-0.2656220857139274,0.8526638282828739],[0.7259603693529442,0.25428467532034965],[0.4577253912481767,-0.2358809079980879],[0.9722462145222105,0.13128550836973255],[0.4089349951770505,-0.09503914544452634],[0.9718156747909192,0.3524307824261209],[1.2009353774940565,-0.25004126389987974],[1.271791635779178,-0.07571928320750206],[0.36784476124502913,-0.23743021661715671],[0.8918396050420891,-0.1029336332277948],[0.4501578013678095,-0.13188266835015783]])+np.array([10,0]).reshape(1,-1)\n",
    "y = np.array([1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0,-1.0])\n",
    "\n",
    "hat_w = perceptron(X, y, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.49468903]\n",
      " [34.08611021]\n",
      " [ 3.        ]]\n",
      "r:  11.316316542509355\n",
      "iteration_bound:  78150.30109461867\n"
     ]
    }
   ],
   "source": [
    "# Part 2\n",
    "\n",
    "print(hat_w)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_new = np.c_[X, np.ones(X.shape[0])]\n",
    "abs_arr = []\n",
    "\n",
    "for i in X_new:\n",
    "    abs_arr.append(np.sqrt(i[0]**2+i[1]**2+i[2]**2))\n",
    "r = np.max(abs_arr)\n",
    "print(\"r: \", r)\n",
    "w_star = hat_w/np.min(np.dot(X_new,hat_w).T * y)\n",
    "w_norm = np.linalg.norm(w_star)\n",
    "\n",
    "#iteration_bound = r*2*w_norm*2\n",
    "iteration_bound = r**2*w_norm**2\n",
    "print(\"iteration_bound: \",iteration_bound)\n",
    "\n",
    "iteration_bound = 78150.30109461867"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 2\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "For this problem you will need the [pandas](https://pandas.pydata.org/) package and the [sklearn](https://scikit-learn.org/stable/) package. If you download the updated `data` folder from the course website you will find a file called `indoor_train.csv`, this file includes a bunch of positions in (X,Y,Z) and also a location number. The idea is to assign a room number (Location) to the coordinates (X,Y,Z).\n",
    "\n",
    "1. [2p] Take the data in the file `indoor_train.csv` and load it using pandas into a dataframe `df_train`\n",
    "2. [3p] From this dataframe `df_train`, create two numpy arrays, one `Xtrain` and `Ytrain`, they should have sizes `(1154,3)` and `(1154,)` respectively. Their `dtype` should be `float64` and `int64` respectively.\n",
    "3. [3p] Train a Support Vector Classifier, `sklearn.svc.SVC`, on `Xtrain, Ytrain` with `kernel='linear'` and name the trained model `svc_train`.\n",
    "\n",
    "To mimic how [kaggle](https://www.kaggle.com/) works, the Autograder has access to a hidden test-set and will test your fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position X</th>\n",
       "      <th>Position Y</th>\n",
       "      <th>Position Z</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>39.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>38.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1154 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Position X   Position Y  Position Z  Location\n",
       "0           32.0         15.0         4.4        18\n",
       "1            8.0         17.0         1.5         9\n",
       "2            4.0         13.0         4.4        13\n",
       "3           39.0         16.0         4.4        18\n",
       "4           34.0         12.0         7.6        15\n",
       "...          ...          ...         ...       ...\n",
       "1149        39.0          9.0         1.5        11\n",
       "1150        38.0         26.0         4.4         6\n",
       "1151         4.0          7.0         1.5         2\n",
       "1152        21.0         19.0         1.5        17\n",
       "1153        25.0         19.0         7.6        19\n",
       "\n",
       "[1154 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('data/indoor_train.csv', encoding='latin-1')  \n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "Xtrain = df_train.iloc[:, 0:3].to_numpy().astype(np.float64)\n",
    "Ytrain = df_train.iloc[:, 3:4].to_numpy().astype(np.int64).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC score 0.9965337954939342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_train = SVC(kernel='linear').fit(Xtrain, Ytrain)\n",
    "\n",
    "score = svc_train.score(Xtrain, Ytrain)\n",
    "\n",
    "print('Linear SVC score %s' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 3\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## SMS spam filtering [8p]\n",
    "\n",
    "In the following problem we will explore SMS spam texts. The dataset is the `SMS Spam Collection Dataset` and we have provided for you a way to load the data. If you run the appropriate cell below, the result will be in the `spam_no_spam` variable. The result is a `list` of `tuples` with the first position in the tuple being the SMS text and the second being a flag `0 = not spam` and `1 = spam`.\n",
    "\n",
    "1. [3p] Let $X$ be the random variable that represents each SMS text (an entry in the list), and let $Y$ represent whether text is spam or not i.e. $Y \\in \\{0,1\\}$. Thus $\\mathbb{P}(Y = 1)$ is the probability that we get a spam. The goal is to estimate:\n",
    "$$\n",
    "    \\mathbb{P}(Y = 1 | \\text{\"free\" or \"prize\" is in } X) \\enspace .\n",
    "$$ \n",
    "That is, the probability that the SMS is spam given that \"free\" or \"prize\" occurs in the SMS. (This is precision). Hint: it is good to remove the upper/lower case of words so that we can also find \"Free\" and \"Prize\"; this can be done with `text.lower()` if `text` a string.\n",
    "\n",
    "2. [3p] Estimate the probability that the word \"free\" or \"prize\" is in the text given that it is spam. (This is recall) I.e. estimate\n",
    "$$\n",
    "    \\mathbb{P}(\\text{\"free\" or \"prize\" is in } X \\mid Y = 1) \\enspace .\n",
    "$$\n",
    "3. [2p] Provide a \"90\\%\" interval of confidence around the true probability from **part 1**. I.e. use the Hoeffding inequality to obtain for your estimate $\\hat P$. Find $l > 0$ such that the following holds:\n",
    "$$\n",
    "    \\mathbb{P}(\\hat P - l \\leq \\mathbb{E}[\\hat P] \\leq \\hat P + l) \\geq 0.9 \\enspace .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Run this cell to get the SMS text data\n",
    "def load_sms():\n",
    "    import csv\n",
    "    lines = []\n",
    "    hamspam = {'ham': 0, 'spam': 1}\n",
    "    with open('data/spam.csv', mode='r',encoding='latin-1') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "        lines = [(line[1],hamspam[line[0]]) for line in reader]\n",
    "        \n",
    "    return lines\n",
    "spam_no_spam = load_sms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 0.8096774193548387\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "spam_no_spam = load_sms()\n",
    "\n",
    "has_prizeORfree_spam = []\n",
    "has_prizeORfree_no_spam = []\n",
    "\n",
    "def contains_whole_word(word, text):\n",
    "    pattern = re.compile(r'\\b{}\\b'.format(re.escape(word)))\n",
    "    return bool(pattern.search(text))\n",
    "\n",
    "for (sms_text, spam_binary) in spam_no_spam:\n",
    "    sms_text_lowercase = sms_text.lower()\n",
    "    #if (\"free\" in sms_text_lowercase) or (\"prize\" in sms_text_lowercase): \n",
    "    if contains_whole_word(\"free\", sms_text_lowercase) or contains_whole_word(\"prize\", sms_text_lowercase):\n",
    "        if spam_binary == 1:\n",
    "            has_prizeORfree_spam.append((sms_text, spam_binary))\n",
    "        elif spam_binary == 0:\n",
    "            has_prizeORfree_no_spam.append((sms_text, spam_binary))\n",
    "            \n",
    "                 \n",
    "\n",
    "estimate = len(has_prizeORfree_spam)/(len(has_prizeORfree_spam)+len(has_prizeORfree_no_spam))\n",
    "print(\"Estimate:\", estimate)\n",
    "\n",
    "\n",
    "# fill in the estimate for part 1 here (should be a number between 0 and 1)\n",
    "problem4_hatP = 0.8096774193548387"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 0.3360107095046854\n"
     ]
    }
   ],
   "source": [
    "#task 3 hatP2\n",
    "import re\n",
    "#import pandas as pd\n",
    "\n",
    "def contains_whole_word(word, text):\n",
    "    pattern = re.compile(r'\\b{}\\b'.format(re.escape(word)))\n",
    "    return bool(pattern.search(text))\n",
    "\n",
    "\n",
    "spam_no_spam = load_sms()\n",
    "\n",
    "is_spam_no_prizeORfree = []\n",
    "is_spam_has_prizeORfree = []\n",
    "#has_prizeORfree = []\n",
    "#array_else = []\n",
    "\n",
    "spam_count_2 = 0\n",
    "\n",
    "for (sms_text, spam_binary) in spam_no_spam:\n",
    "    sms_text_lowercase = sms_text.lower()\n",
    "    if spam_binary==1:\n",
    "        spam_count_2 += 1\n",
    "\n",
    "        if contains_whole_word(\"free\", sms_text_lowercase) or contains_whole_word(\"prize\", sms_text_lowercase):\n",
    "            is_spam_has_prizeORfree.append((sms_text_lowercase, spam_binary))\n",
    "        else:\n",
    "            is_spam_no_prizeORfree.append((sms_text_lowercase, spam_binary))\n",
    "    #if contains_whole_word(\"free\", sms_text_lowercase) or contains_whole_word(\"prize\", sms_text_lowercase):\n",
    "        #has_prizeORfree.append((sms_text_lowercase, spam_binary))\n",
    "\n",
    "\n",
    "\n",
    "estimate = len(is_spam_has_prizeORfree)/( len(is_spam_has_prizeORfree)+len(is_spam_no_prizeORfree) )\n",
    "\n",
    "print(\"Estimate:\", estimate)\n",
    "#the estimate I get is \n",
    "problem4_hatP2 = 0.3360107095046854\n",
    "#but somehow something close to 0.271 is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:  310\n"
     ]
    }
   ],
   "source": [
    "#TASK 3.3\n",
    "import math\n",
    "import re\n",
    "\n",
    "def contains_whole_word(word, text):\n",
    "    pattern = re.compile(r'\\b{}\\b'.format(re.escape(word)))\n",
    "    return bool(pattern.search(text))\n",
    "\n",
    "#calculate the number of text messages that has free or prize in them\n",
    "sms_count_contains_free_or_prize = 0\n",
    "for (sms_text, spam_binary) in spam_no_spam:\n",
    "    sms_text_lowercase = sms_text.lower()\n",
    "    if contains_whole_word(\"free\", sms_text_lowercase) or contains_whole_word(\"prize\", sms_text_lowercase):\n",
    "        sms_count_contains_free_or_prize += 1\n",
    "\n",
    "n = len(has_prizeORfree_spam) + len(has_prizeORfree_no_spam)\n",
    "print(\"n: \", n)\n",
    "\n",
    "epsilon = math.sqrt((-1/(2*n))*math.log(0.1/2))\n",
    "#print(epsilon)\n",
    "\n",
    "# fill in the calculated l from part 3 here\n",
    "problem4_l = 0.0695113389862958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "lx_assignment_number": 3,
  "lx_course_instance": "2023",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
